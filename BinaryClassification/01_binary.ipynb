{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMXrnW4lZbBa"
      },
      "source": [
        "# Tutorial for binary classification using _ImaGene_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nItEjKbGZbBb"
      },
      "source": [
        "This is a short tutorial to learn the basic usage of _ImaGene_ which contains a series of objects in _python_ to interact with _keras_.\n",
        "\n",
        "In this example our aim is to predict whether a given locus is under natural selection from population genomic data.\n",
        "Therefore, we will use _ImaGene_ to perform a binary classification and we will use the classic example of positive selection for lactase persistence in human populations.\n",
        "\n",
        "The C/T(-13910) variant, or rs4988235, is located on chromosome 2 in the _MCM6_ gene but influences the lactase _LCT_ gene. This SNP is associated with the primary haplotype associated with lactose intolerance in European populations.\n",
        "In these populations, the common T allele is associated with lactase persistence. Individuals who are homozygous for C allele are likely to be lactose intolerant.\n",
        "We extracted SNP information from a region of 80k base pairs around the target variant rs4988235 from the 1000 Genomes Project data for all unrelated individuals of CEU population (of European descent).\n",
        "The data is in the form of a VCF file.\n",
        "\n",
        "In this tutorial, you will learn how to:\n",
        "1. read data from VCF file and store it into _ImaGene_ objects,\n",
        "2. run and process simulations to be used for training,\n",
        "3. implement, train and evaluate the neural network,\n",
        "4. deploy the trained network on your genomic data of interest."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloning the repository from GitHub into the Colab environment\n",
        "!git clone https://github.com/Djinho/Project_CNN.git\n",
        "# Changing directory to 'BinaryClassification' within the cloned repo\n",
        "%cd Project_CNN/BinaryClassification\n",
        "# Printing the current working directory\n",
        "!pwd\n"
      ],
      "metadata": {
        "id": "UCntftbPaJNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8WhNHp5ZbBc"
      },
      "source": [
        "Before starting, we need to load the necessary modules in _python_ ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PYTkYBmZbBd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gzip\n",
        "import _pickle as pickle\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import arviz\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models, layers, activations, optimizers, regularizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.transform\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pydot # optional, but required by keras to plot the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JimBAdeXZbBe"
      },
      "source": [
        "... and _ImaGene_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qVlg7rhZbBf"
      },
      "outputs": [],
      "source": [
        "%run -i ../ImaGene.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkQHrg7MZbBf"
      },
      "source": [
        "This tutorial has been tested with:\n",
        "* python 3.9.7\n",
        "* numpy 1.19.5\n",
        "* scipy 1.7.1\n",
        "* keras 2.6.0\n",
        "* tensorflow 2.6.0\n",
        "* scikit-image 0.18.3\n",
        "* scikit-learn 1.0\n",
        "* matplotlib 3.4.3\n",
        "* pydot 1.4.2\n",
        "* pymc3 3.11.4\n",
        "* ipython 7.28.0\n",
        "* jupyterlab 3.1.14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh3LxNkNZbBg"
      },
      "source": [
        "### 1. Read data from VCF file and store it into _ImaGene_ objects\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lw9KaWYDZbBg"
      },
      "outputs": [],
      "source": [
        "file_LCT = ImaFile(nr_samples=198, VCF_file_name='../LCT.CEU.vcf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tQuq7LgZbBh"
      },
      "outputs": [],
      "source": [
        "gene_LCT = file_LCT.read_VCF()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5A2nO9DZbBi"
      },
      "outputs": [],
      "source": [
        "gene_LCT.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b0aRYBJZbBi"
      },
      "source": [
        "As expected, we have one image with 198 rows (equivalent to the number of sampled chromosomal copies) and 2200 columns representing all genomic positions reported.\n",
        "It is likely that not all of these positions will be polymorphic in the CEU sample as the VCF file reports variats across all analysed populations.\n",
        "\n",
        "Similarly, we may want to discard rare variants as they may be more associated to errors or be less informative of the scenario we want to predict.\n",
        "Assume that we want to ignore monomorphic sites and singletons for the derived allele.\n",
        "We can accomplish this with the following command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px181-inZbBi"
      },
      "outputs": [],
      "source": [
        "gene_LCT.filter_freq(0.01);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gene_LCT.plot();"
      ],
      "metadata": {
        "id": "mQi7lI2O1_ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qou0_kEwZbBi"
      },
      "source": [
        "Assume that we wish to sort only rows by their frequency (with the most frequent haplotypes on the top).\n",
        "This can be done with the following command (which will also visualise the resulting image)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BipO9KB9ZbBj"
      },
      "outputs": [],
      "source": [
        "gene_LCT.sort('rows_freq');\n",
        "gene_LCT.plot();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC6jnCY5ZbBj"
      },
      "outputs": [],
      "source": [
        "gene_LCT.convert(flip=True);\n",
        "gene_LCT.plot();\n",
        "gene_LCT.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz5DA1QFZbBj"
      },
      "source": [
        "We finally note that our image has 192 columns now, representing the number of retained SNPs.\n",
        "\n",
        "We can save our _ImaGene_ object in the working `path` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3NBIqJqZbBj"
      },
      "outputs": [],
      "source": [
        "path = './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmCPNhv8ZbBj"
      },
      "outputs": [],
      "source": [
        "gene_LCT.save(file=path + 'gene_LCT');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AMQGYEqZbBj"
      },
      "outputs": [],
      "source": [
        "gene_LCT = load_imagene(file=path + 'gene_LCT');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twi_6Is4ZbBj"
      },
      "source": [
        "### 2. Run and process simulations to be used for training the neural network\n",
        "\n",
        "\n",
        "ImaGene facilitates simulation execution through msms for network training. The script ../generate_dataset.sh employs ../params.txt to configure simulations, with an example file params_binary provided. This example simulates 200,000 loci of 80kbp under neutral evolution or positive selection (allelic selection coefficient: $1.5$%) starting 20kya, with a mutation rate of $1.5e-8$ and recombination rate of $1e-8$. Population simulation follows a 3-epoch model by Marth et al. (2004) for European populations, sampling 198 chromosomal copies. Specify msms directories and simulation storage folder, then execute simulations for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu_djPikZbBj"
      },
      "outputs": [],
      "source": [
        "# if you wish to generate new training data, do not run otherwise\n",
        "import subprocess\n",
        "subprocess.call(\"bash ../generate_dataset.sh params_binary.txt\".split());"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq-A6IqvZbBk"
      },
      "outputs": [],
      "source": [
        "#variable to store path\n",
        "path_sim = './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abywQk5vZbBk"
      },
      "outputs": [],
      "source": [
        "#store simulations into a imafile object\n",
        "file_sim = ImaFile(simulations_folder=path_sim + 'Binary/Simulations1', nr_samples=198, model_name='Marth-3epoch-CEU');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXTN_q7BZbBk"
      },
      "outputs": [],
      "source": [
        "#populate the imagene object specifying the variable we want to estimate/predict\n",
        "gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8DFuvxTZbBk"
      },
      "outputs": [],
      "source": [
        "#Look at the data stored in this object\n",
        "gene_sim.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX7cS9agZbBk"
      },
      "source": [
        "We have 4000 images in this object. Recall that with the first line we simulated 2 classes and retained 2000 data points for each class. All images have 198 rows as expected, as this represents the number of simulated haplotypes. However, images have different number of columns, ranging from $\\approx 130$ to $\\approx 450$ with an average value of $\\approx 295$. The number of columns represents the number of polymorphic sites and fixed derived alleles in a _msms_ file. This number may vary from simulated gene to another.\n",
        "Our observed data for LCT has 192 columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK026WLfZbBk"
      },
      "source": [
        "As mentioned before, _ImaGene_ provides functionalities to manipulate our data. Specifically we can do the following:\n",
        "* convert ancestral/derived to major/minor allele polarisation\n",
        "* filter out columns based on a minimum allele frequency (e.g. 0.01)\n",
        "* sorting rows and columns by frequency (or genetic distance from the most frequent entry)\n",
        "\n",
        "We need to follow the same data processing as the one employed for the real data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfzHmvYgZbBp"
      },
      "outputs": [],
      "source": [
        "gene_sim.filter_freq(0.01);\n",
        "gene_sim.sort('rows_freq');\n",
        "gene_sim.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1h_60DRZbBq"
      },
      "source": [
        "All images must have the same dimensions. You can explore all different options for resizing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3F7FpUsQZbBq"
      },
      "outputs": [],
      "source": [
        "?gene_sim.resize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvuWlP_DZbBq"
      },
      "source": [
        "One possibility would be to resize them to match the dimensions of the real data.\n",
        "In this case it means resize all images to have shape (198, 192) which can be achieved with the following command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axiso3k8ZbBq"
      },
      "outputs": [],
      "source": [
        "gene_sim.resize((198, 192));\n",
        "gene_sim.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUKbFmh7ZbBq"
      },
      "source": [
        "After the data manipulation is done, we need to convert images to proper _numpy_ float matrices,as previously discussed. The following line will do the job (including flipping black/white pixels).\n",
        "Note that the `.convert` method allows you to normalise the data too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKFJzC4yZbBq"
      },
      "outputs": [],
      "source": [
        "gene_sim.convert(flip=True);\n",
        "gene_sim.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Ii8e5SZbBq"
      },
      "source": [
        "Note that in addition to the genomic data, an _ImaGene_ object contains information on the corresponding targets (in this case the selection coefficient, either 0 or 300 in $2N_e$ units with $N_e = 10000$).\n",
        "As an illustration, let's plot one random image per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBmcrIqdZbBq"
      },
      "outputs": [],
      "source": [
        "for sel in gene_sim.classes:\n",
        "    print(sel)\n",
        "    gene_sim.plot(np.where(gene_sim.targets == sel)[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROlihPA3ZbBq"
      },
      "outputs": [],
      "source": [
        "#Randomly shuffle the images to use them in the network\n",
        "gene_sim.subset(get_index_random(gene_sim));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MicEBrbeZbBr"
      },
      "outputs": [],
      "source": [
        "#vectorise the images as requried by keras\n",
        "gene_sim.targets = to_binary(gene_sim.targets);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaS0cluQZbBr"
      },
      "outputs": [],
      "source": [
        "#Save the object it now ready for classification\n",
        "gene_sim.save(file=path + 'gene_sim.binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuXTuumCZbBr"
      },
      "outputs": [],
      "source": [
        "#load imagene object using the function\n",
        "gene_sim = load_imagene(file=path + 'gene_sim.binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-erY_HqZbBr"
      },
      "source": [
        "### 3. Implement, train and evaluate the neural network\n",
        "\n",
        "Now that our data is ready, we can build our network.\n",
        "Specifically, we can build a model in _keras_ with convolutional, pooling and dense layers.\n",
        "In this example we have 3 layers of 2D convolutions and pooling followed by a fully-connected layer.\n",
        "We just need to specify the dimensions of the data in the first layer, and this is specified by the option `input_shape=gene_sim.data.shape[1:]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VJoBVtYZbBr"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid', input_shape=gene_sim.data.shape[1:]),\n",
        "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
        "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                    layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
        "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                    layers.Flatten(),\n",
        "                    layers.Dense(units=128, activation='relu'),\n",
        "                    layers.Dense(units=1, activation='sigmoid')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVJ8YyM8ZbBs"
      },
      "source": [
        "Then, let's compile our _keras_ model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc-F836SZbBs"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSk1ba1VZbBs"
      },
      "source": [
        "Let's look at a summary of the model and plot it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAx0mzKjZbBs"
      },
      "outputs": [],
      "source": [
        "model.summary()\n",
        "plot_model(model, path + 'net.binary.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlKFEBBMZbBs"
      },
      "source": [
        "Now we are ready for doing the training on this first batch of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KCdpXbnZbBs"
      },
      "outputs": [],
      "source": [
        "score = model.fit(gene_sim.data, gene_sim.targets, batch_size=64, epochs=1, verbose=1, validation_split=0.10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZZuK0doZbBs"
      },
      "outputs": [],
      "source": [
        "#intialise the network using ImaNet\n",
        "net_LCT = ImaNet(name='[C32+P]x2+[C64+P]+D128')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_ZoleBFZbBt"
      },
      "outputs": [],
      "source": [
        "#Keep track of scores e.g loss and accuracy\n",
        "net_LCT.update_scores(score);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLH9D7L1ZbBt"
      },
      "source": [
        "Now we need to repeat the whole procedure described above using all remaning batches of data, leaving the last one for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWRXvXQCZbBt"
      },
      "outputs": [],
      "source": [
        "i = 2\n",
        "while i < 10:\n",
        "\n",
        "    print(i)\n",
        "\n",
        "    file_sim = ImaFile(simulations_folder=path_sim + 'Binary/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "    gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000)\n",
        "\n",
        "    gene_sim.filter_freq(0.01)\n",
        "    gene_sim.sort('rows_freq')\n",
        "    gene_sim.resize((198, 192))\n",
        "    gene_sim.convert(flip=True)\n",
        "\n",
        "    gene_sim.subset(get_index_random(gene_sim))\n",
        "    gene_sim.targets = to_binary(gene_sim.targets)\n",
        "\n",
        "    score = model.fit(gene_sim.data, gene_sim.targets, batch_size=64, epochs=1, verbose=1, validation_split=0.10)\n",
        "    net_LCT.update_scores(score)\n",
        "\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvht5LASZbBt"
      },
      "source": [
        "We can plot loss and validation accuracy during the training to check, for instance, for overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoDE9A1iZbBu"
      },
      "outputs": [],
      "source": [
        "net_LCT.plot_train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-On7Hrg3ZbBu"
      },
      "source": [
        "We save (and/or load) the final trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evEnlxYRZbBu"
      },
      "outputs": [],
      "source": [
        "model.save(path + 'model.binary.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j7NmFD8ZbBu"
      },
      "outputs": [],
      "source": [
        "model = load_model(path + 'model.binary.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g69EPOJ2ZbBw"
      },
      "source": [
        "You can also save the network itself (and load it)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B8YY__cZbBx"
      },
      "outputs": [],
      "source": [
        "net_LCT.save(path + 'net_LCT.binary');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lMC7YRJZbBx"
      },
      "outputs": [],
      "source": [
        "net_LCT = load_imanet(path + 'net_LCT.binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoS-cE6jZbBx"
      },
      "source": [
        "Finally, we evaluate the training on the testing dataset, i.e. the last batch of simulated data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuBECYYVZbBx"
      },
      "outputs": [],
      "source": [
        "i = 10\n",
        "file_sim = ImaFile(simulations_folder=path_sim + 'Binary/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "gene_sim_test = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000)\n",
        "\n",
        "gene_sim_test.filter_freq(0.01)\n",
        "gene_sim_test.sort('rows_freq')\n",
        "gene_sim_test.resize((198, 192))\n",
        "gene_sim_test.convert(flip=True)\n",
        "\n",
        "rnd_idx = get_index_random(gene_sim_test) # no need to create this extra variable\n",
        "gene_sim_test.subset(rnd_idx)\n",
        "\n",
        "gene_sim_test.targets = to_binary(gene_sim_test.targets);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1vnUkb8ZbBx"
      },
      "source": [
        "Let's report loss and accuracy on the testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sar-DbTyZbBx"
      },
      "outputs": [],
      "source": [
        "net_LCT.test = model.evaluate(gene_sim_test.data, gene_sim_test.targets, batch_size=None, verbose=0)\n",
        "print(net_LCT.test) # it will report [loss, accuracy]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZlcKHWUZbBx"
      },
      "source": [
        "For a binary (or multiclass) classification, it is convenient to plot the confusion matrix after predicting the responses from the testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng3yBNUIZbBx"
      },
      "outputs": [],
      "source": [
        "net_LCT.predict(gene_sim_test, model)\n",
        "net_LCT.plot_cm(gene_sim_test.classes, text=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNZuk8OAZbBy"
      },
      "source": [
        "### 4. Deploy the trained network on your genomic data of interest\n",
        "\n",
        "Finally we can use the trained network to predict natural selection on our locus of interest.\n",
        "The output of this command will give us the class score (e.g. this can be interpreted as a posterior probability with uniform prior) of said locus under positive selection under the conditions we simulated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5rkdXeYZbBy"
      },
      "outputs": [],
      "source": [
        "print(model.predict(gene_LCT.data, batch_size=None)[0][0])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
