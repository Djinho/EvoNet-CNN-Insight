{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cloning the EvoNet-CNN-Insight GitHub repository\n",
        "!git clone https://github.com/Djinho/EvoNet-CNN-Insight.git\n",
        "\n",
        "%cd /content/EvoNet-CNN-Insight/model_training"
      ],
      "metadata": {
        "id": "yZ3hMXXAMtOL",
        "outputId": "5477b4bc-9292-415d-98f1-c27e7324ec38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EvoNet-CNN-Insight'...\n",
            "remote: Enumerating objects: 894, done.\u001b[K\n",
            "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 894 (delta 81), reused 50 (delta 50), pack-reused 793\u001b[K\n",
            "Receiving objects: 100% (894/894), 1.69 GiB | 31.44 MiB/s, done.\n",
            "Resolving deltas: 100% (168/168), done.\n",
            "Updating files: 100% (197/197), done.\n",
            "/content/EvoNet-CNN-Insight/model_training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lajan9_TAGAS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gzip\n",
        "import _pickle as pickle\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import arviz\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models, layers, activations, optimizers, regularizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.transform\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pydot # optional, but required by keras to plot the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AFY_friAGAT"
      },
      "source": [
        "... and _ImaGene_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zIs9U46aAGAT"
      },
      "outputs": [],
      "source": [
        "%run -i ../ImaGene.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu0XATb8AGAT"
      },
      "source": [
        "This tutorial has been tested with:\n",
        "* python 3.9.7\n",
        "* numpy 1.19.5\n",
        "* scipy 1.7.1\n",
        "* keras 2.6.0\n",
        "* tensorflow 2.6.0\n",
        "* scikit-image 0.18.3\n",
        "* scikit-learn 1.0\n",
        "* matplotlib 3.4.3\n",
        "* pydot 1.4.2\n",
        "* pymc3 3.11.4\n",
        "* ipython 7.28.0\n",
        "* jupyterlab 3.1.14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Qu6YiValAGAV"
      },
      "outputs": [],
      "source": [
        "\n",
        "path_sim = '../'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of valid folders\n",
        "valid_folders = [\n",
        "    'Early_Moderate', 'Early_Strong', 'Early_Weak',\n",
        "    'Late_Moderate', 'Late_Strong', 'Late_Weak',\n",
        "    'Mid_Moderate', 'Mid_Strong', 'Mid_Weak'\n",
        "]\n",
        "\n",
        "# Define a function to check if the selected folder is valid\n",
        "def select_folder(folder_name):\n",
        "    if folder_name in valid_folders:\n",
        "        return folder_name\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid folder name: {folder_name}. Choose from: {valid_folders}\")\n",
        "\n",
        "# Example usage: this should be replaced with actual user input or selection logic\n",
        "selected_folder = select_folder('Early_Strong')\n"
      ],
      "metadata": {
        "id": "A4NgP_eGRAv1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "g7RRS6v3AGAW"
      },
      "outputs": [],
      "source": [
        "file_sim = ImaFile(simulations_folder=path_sim + 'Datasets/' + selected_folder + '/Simulations1', nr_samples=198, model_name='Marth-3epoch-CEU')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qqRpnru_AGAW",
        "outputId": "2bd5d84c-25cd-420a-8eba-34f4d63b4e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 10: '-seed'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/content/EvoNet-CNN-Insight/ImaGene.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgene_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_simulations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'selection_coeff_hetero'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_nrepl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/EvoNet-CNN-Insight/ImaGene.py\u001b[0m in \u001b[0;36mread_simulations\u001b[0;34m(self, parameter_name, max_nrepl, verbose)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;31m# Description for each simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                 \u001b[0mdescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mnr_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpointer\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'segsites: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/EvoNet-CNN-Insight/ImaGene.py\u001b[0m in \u001b[0;36mextract_description\u001b[0;34m(self, file_name, first_line)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Extracting parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Nref'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_msms_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-N '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'nr_chroms'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_msms_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-N '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'nr_replicates'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_msms_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-N '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '-seed'"
          ]
        }
      ],
      "source": [
        "gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTJpnS0eAGAW"
      },
      "outputs": [],
      "source": [
        "gene_sim.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzXbtNsBAGAW"
      },
      "source": [
        "We have 4000 images in this object. Recall that with the first line we simulated 2 classes and retained 2000 data points for each class. All images have 198 rows as expected, as this represents the number of simulated haplotypes. However, images have different number of columns, ranging from $\\approx 130$ to $\\approx 450$ with an average value of $\\approx 295$. The number of columns represents the number of polymorphic sites and fixed derived alleles in a _msms_ file. This number may vary from simulated gene to another.\n",
        "Our observed data for LCT has 192 columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TfVOjsmAGAW"
      },
      "source": [
        "As mentioned before, _ImaGene_ provides functionalities to manipulate our data. Specifically we can do the following:\n",
        "* convert ancestral/derived to major/minor allele polarisation\n",
        "* filter out columns based on a minimum allele frequency (e.g. 0.01)\n",
        "* sorting rows and columns by frequency (or genetic distance from the most frequent entry)\n",
        "\n",
        "We need to follow the same data processing as the one employed for the real data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oas04ZpyAGAX"
      },
      "outputs": [],
      "source": [
        "gene_sim.filter_freq(0.01);\n",
        "gene_sim.sort('rows_freq');\n",
        "gene_sim.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byJqsOZ-AGAX"
      },
      "source": [
        "One possibility would be to resize them to match the dimensions of the real data.\n",
        "In this case it means resize all images to have shape (198, 192) which can be achieved with the following command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xUS9h24AGAY"
      },
      "outputs": [],
      "source": [
        "gene_sim.resize((198, 192));\n",
        "gene_sim.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be1aE-RWAGAY"
      },
      "source": [
        "After the data manipulation is done, we need to convert images to proper _numpy_ float matrices,as previously discussed. The following line will do the job (including flipping black/white pixels).\n",
        "Note that the `.convert` method allows you to normalise the data too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwNc8bMyAGAY"
      },
      "outputs": [],
      "source": [
        "gene_sim.convert(flip=True);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNMuahC4AGAY"
      },
      "source": [
        "Note that in addition to the genomic data, an _ImaGene_ object contains information on the corresponding targets (in this case the selection coefficient, either 0 or 300 in $2N_e$ units with $N_e = 10000$).\n",
        "As an illustration, let's plot one random image per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtT7erobAGAY"
      },
      "outputs": [],
      "source": [
        "for sel in gene_sim.classes:\n",
        "    print(sel)\n",
        "    gene_sim.plot(np.where(gene_sim.targets == sel)[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm-y4AIYAGAZ"
      },
      "source": [
        "Finally we need to randomly shuffle our images before using them for training our network.\n",
        "We can easily accomplish this with the following line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yICKhfmnAGAZ"
      },
      "outputs": [],
      "source": [
        "gene_sim.subset(get_index_random(gene_sim));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwnhupZZAGAa"
      },
      "source": [
        "Our targets represent the 2 possible classes. However, since we are doing a binary classification, we need to vectorise them as required by _keras_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-DMZOmdAGAa"
      },
      "outputs": [],
      "source": [
        "gene_sim.targets = to_binary(gene_sim.targets);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI41u9PxAGAa"
      },
      "source": [
        "The object is now ready to be used for the classification!\n",
        "You can save it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvDkXLSZAGAb"
      },
      "outputs": [],
      "source": [
        "gene_sim.save(file=path + 'gene_sim.binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHpGPBloAGAc"
      },
      "source": [
        "If you want to load an _ImaGene_ object you can use the following function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zu5pt3eUAGAc"
      },
      "outputs": [],
      "source": [
        "gene_sim = load_imagene(file=path + 'gene_sim.binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgKF-ELVAGAe"
      },
      "source": [
        "### 3. Implement, train and evaluate the neural network\n",
        "\n",
        "Now that our data is ready, we can build our network.\n",
        "Specifically, we can build a model in _keras_ with convolutional, pooling and dense layers.\n",
        "In this example we have 3 layers of 2D convolutions and pooling followed by a fully-connected layer.\n",
        "We just need to specify the dimensions of the data in the first layer, and this is specified by the option `input_shape=gene_sim.data.shape[1:]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W53MuVfAGAe"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid', input_shape=gene_sim.data.shape[1:]),\n",
        "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
        "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                    layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
        "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                    layers.Flatten(),\n",
        "                    layers.Dense(units=128, activation='relu'),\n",
        "                    layers.Dense(units=1, activation='sigmoid')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcY4_cwTAGAf"
      },
      "source": [
        "Then, let's compile our _keras_ model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RK6op_5jAGAf"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzyyjOemAGAf"
      },
      "source": [
        "Let's look at a summary of the model and plot it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hn2smDILAGAf"
      },
      "outputs": [],
      "source": [
        "model.summary()\n",
        "plot_model(model, path + 'net.binary.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MONKDnTYAGAf"
      },
      "source": [
        "Now we are ready for doing the training on this first batch of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak914a64AGAf"
      },
      "outputs": [],
      "source": [
        "score = model.fit(gene_sim.data, gene_sim.targets, batch_size=64, epochs=1, verbose=1, validation_split=0.10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0q0P3OVAGAf"
      },
      "source": [
        "Remember that you can save a _keras_ model with `model.save('net.h5')`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU98l_mNAGAg"
      },
      "source": [
        "Now we can initialise a network object _ImaNet_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xfExp-DAGAg"
      },
      "outputs": [],
      "source": [
        "net_LCT = ImaNet(name='[C32+P]x2+[C64+P]+D128')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcIR02gxAGAg"
      },
      "source": [
        "We can keep track of scores (loss and accuracy) across iterations with `.update_scores`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCGHF0k4AGAg"
      },
      "outputs": [],
      "source": [
        "net_LCT.update_scores(score);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DNLZdqRAGAg"
      },
      "source": [
        "Now we need to repeat the whole procedure described above using all remaning batches of data, leaving the last one for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlQPvzhTAGAg"
      },
      "outputs": [],
      "source": [
        "i = 2\n",
        "while i < 10:\n",
        "\n",
        "    print(i)\n",
        "\n",
        "    file_sim = ImaFile(simulations_folder=path_sim + 'Binary/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "    gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000)\n",
        "\n",
        "    gene_sim.filter_freq(0.01)\n",
        "    gene_sim.sort('rows_freq')\n",
        "    gene_sim.resize((198, 192))\n",
        "    gene_sim.convert(flip=True)\n",
        "\n",
        "    gene_sim.subset(get_index_random(gene_sim))\n",
        "    gene_sim.targets = to_binary(gene_sim.targets)\n",
        "\n",
        "    score = model.fit(gene_sim.data, gene_sim.targets, batch_size=64, epochs=1, verbose=1, validation_split=0.10)\n",
        "    net_LCT.update_scores(score)\n",
        "\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNfDMqHKAGAg"
      },
      "source": [
        "We can plot loss and validation accuracy during the training to check, for instance, for overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGUK4RHlAGAg"
      },
      "outputs": [],
      "source": [
        "net_LCT.plot_train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU5Whs8xAGAg"
      },
      "source": [
        "We save (and/or load) the final trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNhthWqTAGAh"
      },
      "outputs": [],
      "source": [
        "model.save(path + 'model.binary.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmOxTLVcAGAh"
      },
      "outputs": [],
      "source": [
        "model = load_model(path + 'model.binary.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIkbkFVyAGAh"
      },
      "source": [
        "You can also save the network itself (and load it)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak7Dy4TiAGAh"
      },
      "outputs": [],
      "source": [
        "net_LCT.save(path + 'net_LCT.binary');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zhu96aXfAGAh"
      },
      "outputs": [],
      "source": [
        "net_LCT = load_imanet(path + 'net_LCT.binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivi3FZCnAGAh"
      },
      "source": [
        "Finally, we evaluate the training on the testing dataset, i.e. the last batch of simulated data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGe9QONgAGAh"
      },
      "outputs": [],
      "source": [
        "i = 10\n",
        "file_sim = ImaFile(simulations_folder=path_sim + 'Binary/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "gene_sim_test = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000)\n",
        "\n",
        "gene_sim_test.filter_freq(0.01)\n",
        "gene_sim_test.sort('rows_freq')\n",
        "gene_sim_test.resize((198, 192))\n",
        "gene_sim_test.convert(flip=True)\n",
        "\n",
        "rnd_idx = get_index_random(gene_sim_test) # no need to create this extra variable\n",
        "gene_sim_test.subset(rnd_idx)\n",
        "\n",
        "gene_sim_test.targets = to_binary(gene_sim_test.targets);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N_89MXQAGAh"
      },
      "source": [
        "Let's report loss and accuracy on the testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wthDgYYKAGAh"
      },
      "outputs": [],
      "source": [
        "net_LCT.test = model.evaluate(gene_sim_test.data, gene_sim_test.targets, batch_size=None, verbose=0)\n",
        "print(net_LCT.test) # it will report [loss, accuracy]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngv1M11XAGAh"
      },
      "source": [
        "For a binary (or multiclass) classification, it is convenient to plot the confusion matrix after predicting the responses from the testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPEjb69hAGAi"
      },
      "outputs": [],
      "source": [
        "net_LCT.predict(gene_sim_test, model)\n",
        "net_LCT.plot_cm(gene_sim_test.classes, text=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}