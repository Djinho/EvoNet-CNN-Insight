{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph4H-zWydWqP"
      },
      "source": [
        "### Data Analysis Pipeline\n",
        "\n",
        "- **Create Simulation**: Represent Recent and weak selection.\n",
        "- **Leverage Pre-trained Model**: Use Baseline Imagene CNN architecture\n",
        "- **Training Regimen**:\n",
        "  - Train for 10 epochs.\n",
        "  - 10 epochs each from batches 1-9 of training data.\n",
        "  - Test on the final batch of unseen data.\n",
        "- **40k Simulations used**\n",
        "-**A100 GPU was used for this training**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Djinho/EvoNet-CNN-Insight.git\n",
        "\n",
        "# Navigate to the cloned repository\n",
        "%cd EvoNet-CNN-Insight/model_training/recent_weak"
      ],
      "metadata": {
        "id": "gZQtOapdWxBE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7067579f-aabb-4b78-80dd-c59ed17ace3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EvoNet-CNN-Insight'...\n",
            "remote: Enumerating objects: 5731, done.\u001b[K\n",
            "remote: Counting objects: 100% (1352/1352), done.\u001b[K\n",
            "remote: Compressing objects: 100% (994/994), done.\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5UU4g1XdWqQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gzip\n",
        "import _pickle as pickle\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, activations, optimizers, regularizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, roc_curve, auc, precision_recall_fscore_support, confusion_matrix\n",
        "\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.transform\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense,Input, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# Set a fixed random seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpaBYfdAdWqS"
      },
      "source": [
        "Run ImaGene.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgeyDstcdWqS"
      },
      "outputs": [],
      "source": [
        "%run -i ../../ImaGene.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPVDFWt9dWqW"
      },
      "outputs": [],
      "source": [
        "#run to make simulations\n",
        "import subprocess\n",
        "subprocess.call(\"bash ../../generate_dataset.sh params_recent_weak.txt\".split());"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CilygMPadWqW"
      },
      "source": [
        " the first iteration of training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8csMaP1dWqW"
      },
      "outputs": [],
      "source": [
        "\n",
        "path_sim = './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDk6e3RDdWqW"
      },
      "outputs": [],
      "source": [
        "file_sim = ImaFile(simulations_folder=path_sim + 'RW/Simulations1', nr_samples=198, model_name='Marth-3epoch-CEU');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzVhCTSydWqW"
      },
      "source": [
        "Then, we populate an _ImaGene_ object by specifying the variable we want to estimate/predict (`selection_coeff_hetero`) and how many data points per class we wish to retain.\n",
        "As a quick example, we will use only 2000 data points per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCQpUsXsdWqW"
      },
      "outputs": [],
      "source": [
        "gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=4000);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_lltiy1dWqW"
      },
      "source": [
        "We can have a look at the data stored in this object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fk6gAdgddWqW"
      },
      "outputs": [],
      "source": [
        "gene_sim.summary();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyZUp2EMdWqY"
      },
      "outputs": [],
      "source": [
        "# Filter simulations based on frequency threshold of 0.01\n",
        "gene_sim.filter_freq(0.01)\n",
        "\n",
        "# Sort simulations by row frequency\n",
        "gene_sim.sort('rows_freq')\n",
        "\n",
        "# Provide summary of the simulation data\n",
        "gene_sim.summary()\n",
        "# Resize simulation data to (198, 192)\n",
        "gene_sim.resize((198, 192))\n",
        "\n",
        "# Provide summary of the simulation data\n",
        "gene_sim.summary()\n",
        "# Convert simulation data with data augmentation (flip)\n",
        "gene_sim.convert(flip=True)\n",
        "\n",
        "# Provide summary of the simulation data\n",
        "gene_sim.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoRS8fbydWqZ"
      },
      "source": [
        "information on the corresponding targets (in this case the selection coefficient, either 0 or selection coefficient of choice in $2N_e$ units with $N_e = 10000$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j9ACqSTdWqZ"
      },
      "outputs": [],
      "source": [
        "for sel in gene_sim.classes:\n",
        "    print(sel)\n",
        "    gene_sim.plot(np.where(gene_sim.targets == sel)[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-K5TWEFdWqZ"
      },
      "outputs": [],
      "source": [
        "# Subset the simulation data with random indices\n",
        "gene_sim.subset(get_index_random(gene_sim))\n",
        "\n",
        "# Convert targets to binary format\n",
        "gene_sim.targets = to_binary(gene_sim.targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7aKeOVZRmjn"
      },
      "source": [
        "Transfer Learning with VGG16 model\n",
        "> Applied the data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtCuHEOTdWqb"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid', input_shape=gene_sim.data.shape[1:]),\n",
        "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
        "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                    layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
        "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                    layers.Flatten(),\n",
        "                    layers.Dense(units=128, activation='relu'),\n",
        "                    layers.Dense(units=1, activation='sigmoid')])\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkhiQZWHdWqc"
      },
      "outputs": [],
      "source": [
        "score = model.fit(gene_sim.data, gene_sim.targets, batch_size=64, epochs=1, verbose=1, validation_split=0.10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdo1QQY5dWqc"
      },
      "outputs": [],
      "source": [
        "net_LCT = ImaNet(name='AW_VGG16')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruRCBgdOdWqc"
      },
      "outputs": [],
      "source": [
        "net_LCT.update_scores(score);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkAh9JwzdWqc"
      },
      "outputs": [],
      "source": [
        "i = 2\n",
        "all_scores = {\n",
        "    'loss': [],\n",
        "    'val_loss': [],\n",
        "    'accuracy': [],\n",
        "    'val_accuracy': []\n",
        "}\n",
        "\n",
        "# Loop to iterate through different simulation datasets\n",
        "while i < 10:\n",
        "    print(i)\n",
        "\n",
        "    # Create ImaFile object for the specified simulation folder and model\n",
        "    file_sim = ImaFile(simulations_folder=path_sim + 'RW/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "\n",
        "    # Read the simulation data\n",
        "    gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=4000)\n",
        "\n",
        "    # Filter simulations based on frequency threshold\n",
        "    gene_sim.filter_freq(0.01)\n",
        "\n",
        "    # Sort simulations by row frequency\n",
        "    gene_sim.sort('rows_freq')\n",
        "\n",
        "    # Resize simulation data to the required dimensions\n",
        "    gene_sim.resize((198, 192))\n",
        "\n",
        "    # Convert simulation data (flip=True allows for data augmentation)\n",
        "    gene_sim.convert(flip=True)\n",
        "\n",
        "    # Get a random subset of indices and subset the simulation data\n",
        "    gene_sim.subset(get_index_random(gene_sim))\n",
        "\n",
        "    # Convert targets to binary format\n",
        "    gene_sim.targets = to_binary(gene_sim.targets)\n",
        "\n",
        "    # Train the model on the current subset of simulation data\n",
        "   score = model.fit(gene_sim.data, gene_sim.targets, batch_size=64, epochs=10, verbose=1, validation_split=0.20)\n",
        "    net_LCT.update_scores(score)\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    # Update scores with the current training results\n",
        "    all_scores['loss'].extend(score.history['loss'])\n",
        "    all_scores['val_loss'].extend(score.history['val_loss'])\n",
        "    all_scores['accuracy'].extend(score.history['accuracy'])\n",
        "    all_scores['val_accuracy'].extend(score.history['val_accuracy'])\n",
        "\n",
        "    # Increment the index for the next iteration\n",
        "    i += 1\n",
        "\n",
        "# Define the number of epochs for plotting\n",
        "epochs = range(1, len(all_scores['loss']) + 1)\n",
        "\n",
        "# Create a figure for plotting\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, all_scores['loss'], 'bo', label='Training loss')\n",
        "plt.plot(epochs, all_scores['val_loss'], 'b', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, all_scores['accuracy'], 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, all_scores['val_accuracy'], 'b', label='Validation accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Better Plotting visualisation"
      ],
      "metadata": {
        "id": "200hF4qcgVVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the number of epochs for plotting\n",
        "epochs = range(1, len(all_scores['loss']) + 1)\n",
        "\n",
        "# Function to smooth the data for better visualization (optional)\n",
        "def smooth_curve(points, factor=0.8):\n",
        "    smoothed_points = []\n",
        "    for point in points:\n",
        "        if smoothed_points:\n",
        "            previous = smoothed_points[-1]\n",
        "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "            smoothed_points.append(point)\n",
        "    return smoothed_points\n",
        "\n",
        "# Create a figure for plotting with better visualization settings\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, smooth_curve(all_scores['loss']), 'bo-', label='Training Loss')\n",
        "plt.plot(epochs, smooth_curve(all_scores['val_loss']), 'ro-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, smooth_curve(all_scores['accuracy']), 'bo-', label='Training Accuracy')\n",
        "plt.plot(epochs, smooth_curve(all_scores['val_accuracy']), 'ro-', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BHIH6HDbgLzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57pzB2ZVdWqd"
      },
      "source": [
        "Evaluate the training on the testing dataset, Which is the last batch of the the 10th simulation in the file\n",
        "The log the testing validation and loss alongside the F1,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkvIbavWdWqd"
      },
      "outputs": [],
      "source": [
        "# Set the simulation index\n",
        "i = 10\n",
        "\n",
        "# Create an ImaFile object for the specified simulation folder and model\n",
        "file_sim = ImaFile(simulations_folder=path_sim + 'RW/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "\n",
        "# Read the simulation data with the specified parameter and maximum number of replicates\n",
        "gene_sim_test = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=4000)\n",
        "\n",
        "# Filter the simulations based on a frequency threshold of 0.01\n",
        "gene_sim_test.filter_freq(0.01)\n",
        "\n",
        "# Sort the simulations by row frequency\n",
        "gene_sim_test.sort('rows_freq')\n",
        "\n",
        "# Resize the simulation data to the specified dimensions (198, 192)\n",
        "gene_sim_test.resize((198, 192))\n",
        "\n",
        "# Convert the simulation data with data augmentation (flip=True)\n",
        "gene_sim_test.convert(flip=True)\n",
        "\n",
        "# Get a random subset of indices and subset the simulation data\n",
        "rnd_idx = get_index_random(gene_sim_test)  # no need to create this extra variable\n",
        "gene_sim_test.subset(rnd_idx)\n",
        "\n",
        "# Convert the targets to binary format\n",
        "gene_sim_test.targets = to_binary(gene_sim_test.targets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG-_g8fyhwnO"
      },
      "outputs": [],
      "source": [
        "\n",
        "net_LCT.test = model.evaluate(gene_sim_test.data, gene_sim_test.targets, batch_size=None, verbose=0)\n",
        "print(net_LCT.test) # it will report [loss, accuracy]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYa_mcCDi7kp"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the validation data\n",
        "predictions = model.predict(gene_sim_test.data)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(gene_sim_test.targets, predictions.round())\n",
        "\n",
        "# Calculate precision, recall, and F-score\n",
        "precision, recall, fscore, _ = precision_recall_fscore_support(gene_sim_test.targets, predictions.round(), average='binary')\n",
        "\n",
        "# Recall is equivalent to sensitivity\n",
        "sensitivity = recall\n",
        "\n",
        "# Compute ROC curve and AUC (Area Under the Curve)\n",
        "fpr, tpr, _ = roc_curve(gene_sim_test.targets, predictions)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:0.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Print additional metrics\n",
        "print(f'F1 Score: {f1}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall (Sensitivity): {sensitivity}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_Gpu1ELhxwI"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data using the trained model and store the results in net_LCT\n",
        "net_LCT.predict(gene_sim_test, model)\n",
        "\n",
        "# Plot the confusion matrix of the predictions against the true classes, with text labels for clarity\n",
        "net_LCT.plot_cm(gene_sim_test.classes, text=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4aTbVzFy-WGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RauARMTt8wSD"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}