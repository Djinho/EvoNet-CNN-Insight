{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK3KvnjK-QcE"
      },
      "source": [
        "Data Analysis Pipeline:\n",
        "\n",
        "\n",
        "*  Clone the repo to carry the dependencies over and to invoke imagene.py.\n",
        "*  Import all necessary modules.\n",
        "\n",
        "\n",
        "*   Simulate data for strong and ancient selection selrange = seq 0 300 300 / timerange = 0.1, 100kya\n",
        "\n",
        "*   Build and compile baseline model.Gather Baseline metrics e.g accuracy, F1 and confusion matrixes\n",
        "\n",
        "\n",
        "*   Train model on training data and gather metrics.\n",
        "\n",
        "*   Test trained network on unseen data. The 10th Batch of Data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloning the GitHub repository\n",
        "!git clone https://github.com/Djinho/EvoNet-CNN-Insight.git\n",
        "\n",
        "# Change directories into the specified directory\n",
        "%cd EvoNet-CNN-Insight/model_training/Ancient_weak\n",
        "\n"
      ],
      "metadata": {
        "id": "R_VVQbWtDaI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9u8r4IE-QcG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gzip\n",
        "import _pickle as pickle\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import arviz\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, optimizers, regularizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.transform\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, roc_curve, auc\n",
        "import pydot  # Optional, but required by keras to plot the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgbCr3IL-QcH"
      },
      "outputs": [],
      "source": [
        "%run -i ../../ImaGene.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oneTA-Ou-QcJ"
      },
      "outputs": [],
      "source": [
        "path = './'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtD-SiZf-QcK"
      },
      "source": [
        "ImaGene uses msms for simulations to train networks. Run generate_dataset.sh with params.txt. Simulates 200,000 loci (80kbp) under neutral evolution or positive selection (additive effect, s=300). Selection starts 100kya (allele frequency 0.01), mutation rate 1.5e-8, recombination rate 1e-8. Follows a 3-epoch model (Marth et al. 2004) for a European population, sampling 198 chromosomal copies. The script splits simulations into batches for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpJ0fu9--QcK"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "# Run the simulation script with specified parameters\n",
        "subprocess.call(\"bash ../../generate_dataset.sh params_Ancient_weak.txt\".split());\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_sim = './'\n",
        "\n",
        "# Initialize variables to store training metrics and total number of epochs\n",
        "total_epochs = 0\n",
        "losses = []\n",
        "val_losses = []\n",
        "accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Loop to iterate through different simulation datasets\n",
        "i = 1\n",
        "while i <= 9:  # Only iterate from 1 to 9 for training\n",
        "    print(f'Processing batch {i}')\n",
        "\n",
        "    # Simulations\n",
        "    file_sim = ImaFile(simulations_folder=path_sim + 'AW/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "    gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000)\n",
        "\n",
        "    # Manipulate data:\n",
        "    # Filter out monomorphic sites, sort rows by genetic distance\n",
        "    gene_sim.filter_freq(0.01)\n",
        "    gene_sim.sort('rows_freq')\n",
        "    gene_sim.resize((198, 192))\n",
        "    gene_sim.convert(flip=True)\n",
        "\n",
        "    # Randomize data\n",
        "    gene_sim.subset(get_index_random(gene_sim))\n",
        "\n",
        "    # Convert targets to binary data\n",
        "    gene_sim.targets = to_binary(gene_sim.targets)\n",
        "\n",
        "    # At the first iteration, we build the model\n",
        "    if i == 1:\n",
        "        model = models.Sequential([\n",
        "            layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu',\n",
        "                          kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid',\n",
        "                          input_shape=gene_sim.data.shape[1:]),\n",
        "            layers.MaxPooling2D(pool_size=(2,2)),\n",
        "            layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu',\n",
        "                          kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
        "            layers.MaxPooling2D(pool_size=(2,2)),\n",
        "            layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu',\n",
        "                          kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
        "            layers.MaxPooling2D(pool_size=(2,2)),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(units=128, activation='relu'),\n",
        "            layers.Dense(units=1, activation='sigmoid')\n",
        "        ])\n",
        "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        net_LCT = ImaNet(name='[C32+P]x2+[C64+P]+D128')\n",
        "\n",
        "    # Training for iterations from 1 to 9\n",
        "    score = model.fit(gene_sim.data, gene_sim.targets, batch_size=64, epochs=1, verbose=1, validation_split=0.10)\n",
        "    losses.extend(score.history['loss'])\n",
        "    val_losses.extend(score.history['val_loss'])\n",
        "    accuracies.extend(score.history['accuracy'])\n",
        "    val_accuracies.extend(score.history['val_accuracy'])\n",
        "    total_epochs += len(score.history['loss'])\n",
        "    net_LCT.update_scores(score)\n",
        "\n",
        "    # Increment the loop counter\n",
        "    i += 1\n",
        "\n",
        "# Print the total number of epochs\n",
        "print(f'Total epochs trained: {total_epochs}')\n",
        "\n",
        "# Plot the loss and validation loss over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(total_epochs), losses, label='Training Loss')\n",
        "plt.plot(range(total_epochs), val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Decay Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the accuracy and validation accuracy over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(total_epochs), accuracies, label='Training Accuracy')\n",
        "plt.plot(range(total_epochs), val_accuracies, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fikMO9TQV85c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the 10th batch\n",
        "i = 10\n",
        "file_sim = ImaFile(simulations_folder=path_sim + 'AW/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "gene_sim_test = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000)\n",
        "\n",
        "gene_sim_test.filter_freq(0.01)\n",
        "gene_sim_test.sort('rows_freq')\n",
        "gene_sim_test.resize((198, 192))\n",
        "gene_sim_test.convert(flip=True)\n",
        "\n",
        "rnd_idx = get_index_random(gene_sim_test) # no need to create this extra variable\n",
        "gene_sim_test.subset(rnd_idx)\n",
        "\n",
        "gene_sim_test.targets = to_binary(gene_sim_test.targets)\n",
        "\n",
        "# Report loss and accuracy on the testing set\n",
        "net_LCT.test = model.evaluate(gene_sim_test.data, gene_sim_test.targets, batch_size=None, verbose=0)\n",
        "print(net_LCT.test)  # it will report [loss, accuracy]\n",
        "\n",
        "# Add ROC and AUC calculation and plotting\n",
        "y_pred_prob = model.predict(gene_sim_test.data)\n",
        "fpr, tpr, _ = roc_curve(gene_sim_test.targets, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(gene_sim_test.targets, y_pred).ravel()\n",
        "\n",
        "# Calculate sensitivity (recall)\n",
        "sensitivity = recall_score(gene_sim_test.targets, y_pred)\n",
        "\n",
        "# Calculate specificity\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(gene_sim_test.targets, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(gene_sim_test.targets, y_pred)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"Sensitivity (Recall): {sensitivity:.2f}\")\n",
        "print(f\"Specificity: {specificity:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "id": "3Mr6Hn6Zi3Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ywZ9OL4-QcP"
      },
      "source": [
        "We save (and/or load) the final trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC1Qh3zu-QcP"
      },
      "outputs": [],
      "source": [
        "model.save(path + 'model.AW.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hAa3CRO-QcP"
      },
      "outputs": [],
      "source": [
        "model = load_model(path + 'model.AW.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laW632Lh-QcP"
      },
      "source": [
        "Finally, we evaluate the training on the testing dataset, which is the 10th batch of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl6AgDO9-QcQ"
      },
      "source": [
        "For a binary (or multiclass) classification, it is convenient to plot the confusion matrix after predicting the responses from the testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEZFWDyG-QcQ"
      },
      "outputs": [],
      "source": [
        "net_LCT.predict(gene_sim_test, model)\n",
        "net_LCT.plot_cm(gene_sim_test.classes, text=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Zw8uIL4Il-M"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}