{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK3KvnjK-QcE"
      },
      "source": [
        "Data Analysis Pipeline:\n",
        "\n",
        "\n",
        "*  Clone the repo to carry the dependencies over and to invoke imagene.py.\n",
        "*  Import all necessary modules.\n",
        "\n",
        "\n",
        "*   Simulate data for moderate and ancient selection selrange = seq 0 200 200 / timerange = 0.1, 100kya\n",
        "\n",
        "*   Build and compile baseline model.Gather Baseline metrics e.g accuracy, F1 and confusion matrixes\n",
        "\n",
        "\n",
        "*   Train model on training data and gather metrics.\n",
        "\n",
        "*   Test trained network on unseen data. The 10th Batch of Data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloning the GitHub repository\n",
        "!git clone https://github.com/Djinho/EvoNet-CNN-Insight.git\n",
        "\n",
        "# Change directories into the specified directory\n",
        "%cd EvoNet-CNN-Insight/model_training/Ancient_moderate\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_VVQbWtDaI-",
        "outputId": "6db353a7-c154-4f55-9c75-d162621a6b0f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EvoNet-CNN-Insight'...\n",
            "remote: Enumerating objects: 3732, done.\u001b[K\n",
            "remote: Counting objects: 100% (548/548), done.\u001b[K\n",
            "remote: Compressing objects: 100% (301/301), done.\u001b[K\n",
            "remote: Total 3732 (delta 372), reused 314 (delta 247), pack-reused 3184\u001b[K\n",
            "Receiving objects: 100% (3732/3732), 4.74 GiB | 26.58 MiB/s, done.\n",
            "Resolving deltas: 100% (1273/1273), done.\n",
            "Updating files: 100% (155/155), done.\n",
            "/content/EvoNet-CNN-Insight/model_training/Ancient_moderate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T9u8r4IE-QcG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gzip\n",
        "import _pickle as pickle\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import arviz\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, optimizers, regularizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.transform\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, roc_curve, auc\n",
        "import pydot  # Optional, but required by keras to plot the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KgbCr3IL-QcH"
      },
      "outputs": [],
      "source": [
        "%run -i ../../ImaGene.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oneTA-Ou-QcJ"
      },
      "outputs": [],
      "source": [
        "path = './'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtD-SiZf-QcK"
      },
      "source": [
        "ImaGene uses msms for simulations to train networks. Run generate_dataset.sh with params.txt. Simulates 200,000 loci (80kbp) under neutral evolution or positive selection (additive effect, s=200). Selection starts 100kya (allele frequency 0.01), mutation rate 1.5e-8, recombination rate 1e-8. Follows a 3-epoch model (Marth et al. 2004) for a European population, sampling 198 chromosomal copies. The script splits simulations into batches for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpJ0fu9--QcK"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "# Run the simulation script with specified parameters\n",
        "subprocess.call(\"bash ../generate_dataset.sh params_Ancient_moderate.txt\".split());\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utIwRbBK-QcK"
      },
      "outputs": [],
      "source": [
        "\n",
        "path_sim = './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MchXp6DQ-QcK"
      },
      "outputs": [],
      "source": [
        "# Initialize the ImaFile object with specified folder, number of samples, and model name\n",
        "file_sim = ImaFile(simulations_folder=path_sim + 'AM/Simulations1', nr_samples=198, model_name='Marth-3epoch-CEU');\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WJsx4eN-QcK"
      },
      "outputs": [],
      "source": [
        "# Read simulation data from the specified folder, filtering by 'selection_coeff_hetero' and limiting to 2000 replications\n",
        "gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FGJbyMg-QcL"
      },
      "outputs": [],
      "source": [
        "# Filter the simulation data to include only those with a frequency of 0.01\n",
        "gene_sim.filter_freq(0.01);\n",
        "\n",
        "# Sort the filtered simulation data by 'rows_freq'\n",
        "gene_sim.sort('rows_freq');\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tYlmeE6-QcL"
      },
      "outputs": [],
      "source": [
        "# Resize the simulation data to a matrix with dimensions 198x192\n",
        "gene_sim.resize((198, 192));\n",
        "\n",
        "# Convert the simulation data, applying a flip transformation\n",
        "gene_sim.convert(flip=True);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VXYbA4b-QcM"
      },
      "source": [
        "shuffle images before using them for training network.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSV9FO0y-QcM"
      },
      "outputs": [],
      "source": [
        "# Create a random subset of the simulation data\n",
        "gene_sim.subset(get_index_random(gene_sim));\n",
        "\n",
        "# Convert the targets of the simulation data to binary\n",
        "gene_sim.targets = to_binary(gene_sim.targets);\n",
        "\n",
        "# Save the processed simulation data to a binary file\n",
        "gene_sim.save(file=path + 'gene_sim.binary');\n",
        "\n",
        "# Load the simulation data from the saved binary file\n",
        "gene_sim = load_imagene(file=path + 'gene_sim.binary');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3WdFdhP-QcN"
      },
      "source": [
        "Build and compile the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jIcAFB5-QcN"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid', input_shape=gene_sim.data.shape[1:]),\n",
        "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
        "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                    layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
        "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                    layers.Flatten(),\n",
        "                    layers.Dense(units=128, activation='relu'),\n",
        "                    layers.Dense(units=1, activation='sigmoid')])\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_NyM2oX-QcN"
      },
      "source": [
        "summary of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWw5ViWO-QcN"
      },
      "outputs": [],
      "source": [
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7rSsKW6-QcO"
      },
      "outputs": [],
      "source": [
        "net_LCT = ImaNet(name='[C32+P]x2+[C64+P]+D128')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtjM_zR9-QcO"
      },
      "source": [
        "train batches from 1-9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4-vMnDN-QcO"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Initialize variables to store training metrics and total number of epochs\n",
        "total_epochs = 0\n",
        "losses = []\n",
        "val_losses = []\n",
        "accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Loop to iterate through different simulation datasets\n",
        "i = 1\n",
        "while i < 10:\n",
        "    print(i)\n",
        "\n",
        "    # Load simulation data for the current iteration\n",
        "    file_sim = ImaFile(simulations_folder=path_sim + 'AM/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "    gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000)\n",
        "\n",
        "    # Filter, sort, and preprocess the simulation data\n",
        "    gene_sim.filter_freq(0.01)\n",
        "    gene_sim.sort('rows_freq')\n",
        "    gene_sim.resize((198, 192))\n",
        "    gene_sim.convert(flip=True)\n",
        "\n",
        "    # Create a random subset and convert targets to binary\n",
        "    gene_sim.subset(get_index_random(gene_sim))\n",
        "    gene_sim.targets = to_binary(gene_sim.targets)\n",
        "\n",
        "    # Train the model for one epoch on the current dataset\n",
        "    score = model.fit(gene_sim.data, gene_sim.targets, batch_size=64, epochs=1, verbose=1, validation_split=0.10)\n",
        "\n",
        "    # Append the loss, validation loss, accuracy, and validation accuracy values for each epoch\n",
        "    losses.extend(score.history['loss'])\n",
        "    val_losses.extend(score.history['val_loss'])\n",
        "    accuracies.extend(score.history['accuracy'])\n",
        "    val_accuracies.extend(score.history['val_accuracy'])\n",
        "\n",
        "    # Update the total number of epochs trained\n",
        "    total_epochs += len(score.history['loss'])\n",
        "\n",
        "    # Update scores in the net_LCT object (assumed to be defined elsewhere)\n",
        "    net_LCT.update_scores(score)\n",
        "\n",
        "    # Increment the loop counter\n",
        "    i += 1\n",
        "\n",
        "# Print the total number of epochs\n",
        "print(f'Total epochs trained: {total_epochs}')\n",
        "\n",
        "# Save the loss, validation loss, accuracy, and validation accuracy to a CSV file\n",
        "with open('training_metrics.csv', 'w', newline='') as csvfile:\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "    csvwriter.writerow(['Epoch', 'Training Loss', 'Validation Loss', 'Training Accuracy', 'Validation Accuracy'])\n",
        "    for epoch in range(total_epochs):\n",
        "        training_loss = losses[epoch] if epoch < len(losses) else ''\n",
        "        validation_loss = val_losses[epoch] if epoch < len(val_losses) else ''\n",
        "        training_accuracy = accuracies[epoch] if epoch < len(accuracies) else ''\n",
        "        validation_accuracy = val_accuracies[epoch] if epoch < len(val_accuracies) else ''\n",
        "        csvwriter.writerow([epoch + 1, training_loss, validation_loss, training_accuracy, validation_accuracy])\n",
        "\n",
        "# Plot the loss and validation loss over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(total_epochs), losses, label='Training Loss')\n",
        "plt.plot(range(total_epochs), val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Decay Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the accuracy and validation accuracy over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(total_epochs), accuracies, label='Training Accuracy')\n",
        "plt.plot(range(total_epochs), val_accuracies, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhwevgDT-QcP"
      },
      "source": [
        "We can plot loss and validation accuracy during the training to check, for instance, for overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ywZ9OL4-QcP"
      },
      "source": [
        "We save (and/or load) the final trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC1Qh3zu-QcP"
      },
      "outputs": [],
      "source": [
        "model.save(path + 'model.AM.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hAa3CRO-QcP"
      },
      "outputs": [],
      "source": [
        "model = load_model(path + 'model.AM.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laW632Lh-QcP"
      },
      "source": [
        "Finally, we evaluate the training on the testing dataset, which is the 10th batch of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WQtQPBF-QcP"
      },
      "outputs": [],
      "source": [
        "# Set the iteration number\n",
        "i = 10\n",
        "\n",
        "# Initialize the ImaFile object with specified folder, number of samples, and model name for the test simulations\n",
        "file_sim = ImaFile(simulations_folder=path_sim + 'AM/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "\n",
        "# Read the simulation data for the test set\n",
        "gene_sim_test = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000)\n",
        "\n",
        "# Filter the simulation data to include only those with a frequency of 0.01\n",
        "gene_sim_test.filter_freq(0.01)\n",
        "\n",
        "# Sort the filtered simulation data by 'rows_freq'\n",
        "gene_sim_test.sort('rows_freq')\n",
        "\n",
        "# Resize the simulation data to a matrix with dimensions 198x192\n",
        "gene_sim_test.resize((198, 192))\n",
        "\n",
        "# Convert the simulation data, applying a flip transformation\n",
        "gene_sim_test.convert(flip=True)\n",
        "\n",
        "# Create a random subset of the test simulation data\n",
        "rnd_idx = get_index_random(gene_sim_test)\n",
        "gene_sim_test.subset(rnd_idx)\n",
        "\n",
        "# Convert the targets of the test simulation data to binary\n",
        "gene_sim_test.targets = to_binary(gene_sim_test.targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RzUUL7N-QcQ"
      },
      "source": [
        "Let's report loss and accuracy on the testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfnyOoDI-QcQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "net_LCT.test = model.evaluate(gene_sim_test.data, gene_sim_test.targets, batch_size=None, verbose=0)\n",
        "print(net_LCT.test)  # it will report [loss, accuracy]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the following code for ROC and AUC calculation and plotting\n",
        "y_pred_prob = model.predict(gene_sim_test.data)\n",
        "fpr, tpr, _ = roc_curve(gene_sim_test.targets, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(gene_sim_test.targets, y_pred).ravel()\n",
        "\n",
        "# Calculate sensitivity (recall)\n",
        "sensitivity = recall_score(gene_sim_test.targets, y_pred)\n",
        "\n",
        "# Calculate specificity\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(gene_sim_test.targets, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(gene_sim_test.targets, y_pred)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"Sensitivity (Recall): {sensitivity:.2f}\")\n",
        "print(f\"Specificity: {specificity:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")"
      ],
      "metadata": {
        "id": "dsUPWFGlBZcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl6AgDO9-QcQ"
      },
      "source": [
        "For a binary (or multiclass) classification, it is convenient to plot the confusion matrix after predicting the responses from the testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEZFWDyG-QcQ"
      },
      "outputs": [],
      "source": [
        "net_LCT.predict(gene_sim_test, model)\n",
        "net_LCT.plot_cm(gene_sim_test.classes, text=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}