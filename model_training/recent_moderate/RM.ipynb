{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph4H-zWydWqP"
      },
      "source": [
        "### Data Analysis Pipeline\n",
        "\n",
        "- **Create Simulation**: Represent recent and moderate selection.\n",
        "- **Leverage Pre-trained Model**: Use a model trained on recent and strong selection with high accuracy. Model can be considered fit for purpose if 80% accuracy and above\n",
        "- **Training Regimen**:\n",
        "  - Train for 9 epochs.\n",
        "  - 1 epochs each from batches 1-9 of training data.\n",
        "  - Test on the final batch of unseen data.\n",
        "- **40k Simulations used**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Djinho/EvoNet-CNN-Insight.git\n",
        "\n",
        "# Navigate to the cloned repository\n",
        "%cd EvoNet-CNN-Insight/model_training/recent_moderate"
      ],
      "metadata": {
        "id": "MwegN_Tjd-7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5UU4g1XdWqQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gzip\n",
        "import _pickle as pickle\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import arviz\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, activations, optimizers, regularizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, roc_curve, auc, precision_recall_fscore_support, confusion_matrix\n",
        "\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.transform\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pydot # optional, but required by keras to plot the model\n",
        "\n",
        "# Set a fixed random seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpaBYfdAdWqS"
      },
      "source": [
        "Run ImaGene.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgeyDstcdWqS"
      },
      "outputs": [],
      "source": [
        "%run -i ../../ImaGene.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPVDFWt9dWqW"
      },
      "outputs": [],
      "source": [
        "#run to make simulations\n",
        "import subprocess\n",
        "subprocess.call(\"bash ../../generate_dataset.sh params_recent_moderate.txt\".split());"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CilygMPadWqW"
      },
      "source": [
        " the first iteration of training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8csMaP1dWqW"
      },
      "outputs": [],
      "source": [
        "\n",
        "path_sim = './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDk6e3RDdWqW"
      },
      "outputs": [],
      "source": [
        "file_sim = ImaFile(simulations_folder=path_sim + 'RM!/Simulations1', nr_samples=198, model_name='Marth-3epoch-CEU');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzVhCTSydWqW"
      },
      "source": [
        "Then, we populate an _ImaGene_ object by specifying the variable we want to estimate/predict (`selection_coeff_hetero`) and how many data points per class we wish to retain.\n",
        "As a quick example, we will use only 2000 data points per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCQpUsXsdWqW"
      },
      "outputs": [],
      "source": [
        "gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=4000);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_lltiy1dWqW"
      },
      "source": [
        "We can have a look at the data stored in this object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fk6gAdgddWqW"
      },
      "outputs": [],
      "source": [
        "gene_sim.summary();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyZUp2EMdWqY"
      },
      "outputs": [],
      "source": [
        "# Filter simulations based on frequency threshold of 0.01\n",
        "gene_sim.filter_freq(0.01)\n",
        "\n",
        "# Sort simulations by row frequency\n",
        "gene_sim.sort('rows_freq')\n",
        "\n",
        "# Provide summary of the simulation data\n",
        "gene_sim.summary()\n",
        "# Resize simulation data to (198, 192)\n",
        "gene_sim.resize((198, 192))\n",
        "\n",
        "# Provide summary of the simulation data\n",
        "gene_sim.summary()\n",
        "# Convert simulation data with data augmentation (flip)\n",
        "gene_sim.convert(flip=True)\n",
        "\n",
        "# Provide summary of the simulation data\n",
        "gene_sim.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoRS8fbydWqZ"
      },
      "source": [
        "information on the corresponding targets (in this case the selection coefficient, either 0 or selection coefficient of choice in $2N_e$ units with $N_e = 10000$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j9ACqSTdWqZ"
      },
      "outputs": [],
      "source": [
        "for sel in gene_sim.classes:\n",
        "    print(sel)\n",
        "    gene_sim.plot(np.where(gene_sim.targets == sel)[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-K5TWEFdWqZ"
      },
      "outputs": [],
      "source": [
        "# Subset the simulation data with random indices\n",
        "gene_sim.subset(get_index_random(gene_sim))\n",
        "\n",
        "# Convert targets to binary format\n",
        "gene_sim.targets = to_binary(gene_sim.targets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtCuHEOTdWqb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the pre-trained model from the parent directory\n",
        "base_model = load_model('../RS.binary.h5')\n",
        "\n",
        "# Freeze fewer initial layers of the base model\n",
        "for layer in base_model.layers[:-20]:  # Freeze all but the last 20 layers\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add new layers on top of the pre-trained model for fine-tuning\n",
        "model = models.Sequential([\n",
        "    base_model,  # The pre-trained model is added as the base\n",
        "    layers.Flatten(),  # Flatten the output from the base model to feed into dense layers\n",
        "    layers.Dense(units=128, activation='relu'),  # New dense layer with 128 units and ReLU activation\n",
        "    layers.BatchNormalization(),  # Batch Normalization for improved training\n",
        "    layers.Dropout(0.5),  # Dropout for regularization to prevent overfitting\n",
        "    layers.Dense(units=128, activation='relu'),  # Additional dense layer\n",
        "    layers.BatchNormalization(),  # Batch Normalization for improved training\n",
        "    layers.Dropout(0.5),  # Dropout for regularization to prevent overfitting\n",
        "    layers.Dense(units=128, activation='relu'),  # Another dense layer\n",
        "    layers.BatchNormalization(),  # Batch Normalization for improved training\n",
        "    layers.Dropout(0.5),  # Dropout for regularization to prevent overfitting\n",
        "    layers.Dense(units=1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model with an adjusted learning rate\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=0.00005),\n",
        "                     loss='binary_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model to show its architecture\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkhiQZWHdWqc"
      },
      "outputs": [],
      "source": [
        "score = model.fit(gene_sim.data, gene_sim.targets, batch_size=64, epochs=1, verbose=1, validation_split=0.10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdo1QQY5dWqc"
      },
      "outputs": [],
      "source": [
        "net_LCT = ImaNet(name='BaseModel_FineTuned_D128')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruRCBgdOdWqc"
      },
      "outputs": [],
      "source": [
        "net_LCT.update_scores(score);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkAh9JwzdWqc"
      },
      "outputs": [],
      "source": [
        "i = 2\n",
        "all_scores = {\n",
        "    'loss': [],\n",
        "    'val_loss': [],\n",
        "    'accuracy': [],\n",
        "    'val_accuracy': []\n",
        "}\n",
        "\n",
        "# Loop to iterate through different simulation datasets\n",
        "while i < 10:\n",
        "    print(i)\n",
        "\n",
        "    # Create ImaFile object for the specified simulation folder and model\n",
        "    file_sim = ImaFile(simulations_folder=path_sim + 'RM!/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "\n",
        "    # Read the simulation data\n",
        "    gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=4000)\n",
        "\n",
        "    # Filter simulations based on frequency threshold\n",
        "    gene_sim.filter_freq(0.01)\n",
        "\n",
        "    # Sort simulations by row frequency\n",
        "    gene_sim.sort('rows_freq')\n",
        "\n",
        "    # Resize simulation data to the required dimensions\n",
        "    gene_sim.resize((198, 192))\n",
        "\n",
        "    # Convert simulation data (flip=True allows for data augmentation)\n",
        "    gene_sim.convert(flip=True)\n",
        "\n",
        "    # Get a random subset of indices and subset the simulation data\n",
        "    gene_sim.subset(get_index_random(gene_sim))\n",
        "\n",
        "    # Convert targets to binary format\n",
        "    gene_sim.targets = to_binary(gene_sim.targets)\n",
        "\n",
        "    # Train the model on the current subset of simulation data\n",
        "    score = model.fit(gene_sim.data, gene_sim.targets, batch_size=64, epochs=1, verbose=1, validation_split=0.10)\n",
        "\n",
        "    # Update scores with the current training results\n",
        "    all_scores['loss'].extend(score.history['loss'])\n",
        "    all_scores['val_loss'].extend(score.history['val_loss'])\n",
        "    all_scores['accuracy'].extend(score.history['accuracy'])\n",
        "    all_scores['val_accuracy'].extend(score.history['val_accuracy'])\n",
        "\n",
        "    # Increment the index for the next iteration\n",
        "    i += 1\n",
        "\n",
        "# Define the number of epochs for plotting\n",
        "epochs = range(1, len(all_scores['loss']) + 1)\n",
        "\n",
        "# Create a figure for plotting\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, all_scores['loss'], 'bo', label='Training loss')\n",
        "plt.plot(epochs, all_scores['val_loss'], 'b', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, all_scores['accuracy'], 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, all_scores['val_accuracy'], 'b', label='Validation accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVmdhW26dWqd"
      },
      "outputs": [],
      "source": [
        "# Set the appropriate path\n",
        "path = './'\n",
        "# Save the trained model to a file\n",
        "model.save(path + 'RM_transfer_learning.h5')\n",
        "\n",
        "# Load the model from the saved file\n",
        "model = load_model(path + 'RM_transfer_learning.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57pzB2ZVdWqd"
      },
      "source": [
        "Evaluate the training on the testing dataset, Which is the last batch of the the 10th simulation in the file\n",
        "The log the testing validation and loss alongside the F1,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkvIbavWdWqd"
      },
      "outputs": [],
      "source": [
        "# Set the simulation index\n",
        "i = 10\n",
        "\n",
        "# Create an ImaFile object for the specified simulation folder and model\n",
        "file_sim = ImaFile(simulations_folder=path_sim + 'RM!/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "\n",
        "# Read the simulation data with the specified parameter and maximum number of replicates\n",
        "gene_sim_test = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=4000)\n",
        "\n",
        "# Filter the simulations based on a frequency threshold of 0.01\n",
        "gene_sim_test.filter_freq(0.01)\n",
        "\n",
        "# Sort the simulations by row frequency\n",
        "gene_sim_test.sort('rows_freq')\n",
        "\n",
        "# Resize the simulation data to the specified dimensions (198, 192)\n",
        "gene_sim_test.resize((198, 192))\n",
        "\n",
        "# Convert the simulation data with data augmentation (flip=True)\n",
        "gene_sim_test.convert(flip=True)\n",
        "\n",
        "# Get a random subset of indices and subset the simulation data\n",
        "rnd_idx = get_index_random(gene_sim_test)  # no need to create this extra variable\n",
        "gene_sim_test.subset(rnd_idx)\n",
        "\n",
        "# Convert the targets to binary format\n",
        "gene_sim_test.targets = to_binary(gene_sim_test.targets)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data to obtain loss and accuracy\n",
        "net_LCT.test = model.evaluate(gene_sim_test.data, gene_sim_test.targets, batch_size=None, verbose=0)\n",
        "\n",
        "# Print the evaluation results, which include loss and accuracy\n",
        "print(net_LCT.test)  # It will report [loss, accuracy]\n"
      ],
      "metadata": {
        "id": "MG-_g8fyhwnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation data\n",
        "predictions = model.predict(gene_sim_test.data)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(gene_sim_test.targets, predictions.round())\n",
        "\n",
        "# Calculate precision, recall, and F-score\n",
        "precision, recall, fscore, _ = precision_recall_fscore_support(gene_sim_test.targets, predictions.round(), average='binary')\n",
        "\n",
        "# Recall is equivalent to sensitivity\n",
        "sensitivity = recall\n",
        "\n",
        "# Compute ROC curve and AUC (Area Under the Curve)\n",
        "fpr, tpr, _ = roc_curve(gene_sim_test.targets, predictions)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:0.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Print additional metrics\n",
        "print(f'F1 Score: {f1}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall (Sensitivity): {sensitivity}')"
      ],
      "metadata": {
        "id": "jYa_mcCDi7kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data using the trained model and store the results in net_LCT\n",
        "net_LCT.predict(gene_sim_test, model)\n",
        "\n",
        "# Plot the confusion matrix of the predictions against the true classes, with text labels for clarity\n",
        "net_LCT.plot_cm(gene_sim_test.classes, text=True)\n"
      ],
      "metadata": {
        "id": "q_Gpu1ELhxwI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}