{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Optimization for Ancient Scenarios\n",
        "\n",
        " Bayesian Optimization for ancient selection scenarios using the following parameters:\n",
        "- **Number of Trials:** 30\n",
        "- **Number of Simulations Used:** 40,000\n",
        "- **GPU Used:** A100\n"
      ],
      "metadata": {
        "id": "FkPWlD3Ro7EK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "!pip install optuna-integration\n",
        "\n"
      ],
      "metadata": {
        "id": "GRHg6VeRIv4p",
        "outputId": "b8eac03e-bf0b-4ed7-fcf9-fb4e3ab6e892",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 optuna-3.6.1\n",
            "Collecting optuna-integration\n",
            "  Downloading optuna_integration-3.6.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (from optuna-integration) (3.6.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (1.13.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (2.0.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->optuna-integration) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration) (2.1.5)\n",
            "Downloading optuna_integration-3.6.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.4/93.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: optuna-integration\n",
            "Successfully installed optuna-integration-3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4zMiOTwGCc48",
        "outputId": "687fb82c-3ad2-4b2f-c63c-09751aa26908",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EvoNet-CNN-Insight'...\n",
            "remote: Enumerating objects: 5675, done.\u001b[K\n",
            "remote: Counting objects: 100% (1296/1296), done.\u001b[K\n",
            "remote: Compressing objects: 100% (938/938), done.\u001b[K\n",
            "remote: Total 5675 (delta 464), reused 1112 (delta 341), pack-reused 4379\u001b[K\n",
            "Receiving objects: 100% (5675/5675), 8.07 GiB | 16.99 MiB/s, done.\n",
            "Resolving deltas: 100% (2062/2062), done.\n",
            "Updating files: 100% (264/264), done.\n",
            "/content/EvoNet-CNN-Insight/Optimisation_notebooks\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Djinho/EvoNet-CNN-Insight.git\n",
        "\n",
        "# Navigate to the cloned repository\n",
        "%cd EvoNet-CNN-Insight/Optimisation_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i ../ImaGene.py"
      ],
      "metadata": {
        "id": "S7ZFl2RTDD2w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, regularizers, callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "import time\n",
        "import gzip\n",
        "import skimage.transform\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "\n",
        "# Configure logging to file in the current directory with the specified name\n",
        "logging.basicConfig(filename='Ancient_Scenarios_AM.log', level=logging.INFO,\n",
        "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
        "\n",
        "# Function to preprocess data\n",
        "def preprocess_data(simulations_folder, batch_number):\n",
        "    # Create ImaFile object for the specified simulation folder and model\n",
        "    file_sim = ImaFile(simulations_folder=os.path.join(simulations_folder, f'Simulations{batch_number}'), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "\n",
        "    # Read the simulation data\n",
        "    gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=4000)\n",
        "\n",
        "    # Filter simulations based on frequency threshold\n",
        "    gene_sim.filter_freq(0.01)\n",
        "\n",
        "    # Sort simulations by row frequency\n",
        "    gene_sim.sort('rows_freq')\n",
        "\n",
        "    # Resize simulation data to the required dimensions\n",
        "    gene_sim.resize((198, 192))\n",
        "\n",
        "    # Convert simulation data (flip=True allows for data augmentation)\n",
        "    gene_sim.convert(flip=True)\n",
        "\n",
        "    # Get a random subset of indices and subset the simulation data\n",
        "    gene_sim.subset(get_index_random(gene_sim))\n",
        "\n",
        "    # Convert targets to binary format\n",
        "    gene_sim.targets = to_binary(gene_sim.targets)\n",
        "\n",
        "    return gene_sim\n",
        "\n",
        "# Objective function for Optuna optimization\n",
        "def objective(trial, simulations_folder, epochs=1):\n",
        "    # Set random seed\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    # Hyperparameters to be optimized\n",
        "    num_layers = trial.suggest_int('num_layers', 3, 6)  # Limit the number of layers to avoid excessive reduction\n",
        "    filters = [trial.suggest_int(f'filters_{i}', 32, 128) for i in range(num_layers)]  # Adjust filters range\n",
        "    kernel_size = trial.suggest_int('kernel_size', 2, 3)  # Limit the kernel size to avoid excessive reduction\n",
        "    l1 = trial.suggest_float('l1', 1e-6, 1e-2, log=True)\n",
        "    l2 = trial.suggest_float('l2', 1e-6, 1e-2, log=True)\n",
        "    dense_units = trial.suggest_int('dense_units', 64, 256)  # Adjust dense units range\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
        "\n",
        "    # Log the hyperparameters at the start of each trial\n",
        "    logging.info(f'Trial {trial.number} started with hyperparameters: num_layers={num_layers}, filters={filters}, '\n",
        "                 f'kernel_size={kernel_size}, l1={l1}, l2={l2}, dense_units={dense_units}, '\n",
        "                 f'dropout_rate={dropout_rate}, learning_rate={learning_rate}')\n",
        "    print(f'Trial {trial.number} started with hyperparameters: num_layers={num_layers}, filters={filters}, '\n",
        "          f'kernel_size={kernel_size}, l1={l1}, l2={l2}, dense_units={dense_units}, '\n",
        "          f'dropout_rate={dropout_rate}, learning_rate={learning_rate}')\n",
        "\n",
        "    # Building the model based on sampled hyperparameters\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=(198, 192, 1)))  # Define the input layer\n",
        "    for i in range(num_layers):\n",
        "        model.add(layers.Conv2D(filters=filters[i], kernel_size=(kernel_size, kernel_size), strides=(1, 1), activation='relu',\n",
        "                                kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2), padding='same'))  # Use 'same' padding to avoid dimension issues\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())  # Flatten the output for the Dense layers\n",
        "    model.add(layers.Dense(units=dense_units, activation='relu'))  # Add Dense layer\n",
        "    model.add(layers.Dropout(rate=dropout_rate))  # Add Dropout layer\n",
        "    model.add(layers.Dense(units=1, activation='sigmoid'))  # Output layer with sigmoid activation\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)  # Define optimizer\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])  # Compile the model\n",
        "\n",
        "    # Pruning callback to terminate unpromising trials\n",
        "    pruning_callback = TFKerasPruningCallback(trial, 'val_loss')\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Incremental training on 9 batches\n",
        "    best_val_loss = np.inf  # Track the best validation loss\n",
        "    for batch_number in range(1, 10):\n",
        "        gene_sim = preprocess_data(simulations_folder, batch_number)  # Preprocess data\n",
        "        history = model.fit(gene_sim.data, gene_sim.targets, batch_size=64, epochs=epochs, verbose=1, validation_split=0.2,\n",
        "                            callbacks=[early_stopping, pruning_callback])  # Train the model with callbacks\n",
        "\n",
        "        # Get the validation loss for the current epoch\n",
        "        val_loss = min(history.history['val_loss'])\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            trial.report(val_loss, batch_number)\n",
        "            if trial.should_prune():\n",
        "                raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    # Evaluate the model on the 10th batch\n",
        "    gene_sim = preprocess_data(simulations_folder, 10)\n",
        "    evaluation = model.evaluate(gene_sim.data, gene_sim.targets, verbose=1)\n",
        "    return evaluation[1]  # Return the accuracy\n",
        "\n",
        "# Function to run the optimization process\n",
        "def run_optimization():\n",
        "    start_time = time.time()  # Record start time\n",
        "\n",
        "    simulations_folder = '/content/EvoNet-CNN-Insight/model_training/Ancient_moderate/AM'  # Folder for this dataset\n",
        "    logging.info(f\"Starting optimization for {simulations_folder}\")\n",
        "    print(f\"Starting optimization for {simulations_folder}\")\n",
        "\n",
        "    # Create an Optuna study and optimize the objective function\n",
        "    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner(), storage='sqlite:///am_study.db', load_if_exists=True)  # Use SQLite storage\n",
        "    study.optimize(lambda trial: objective(trial, simulations_folder), n_trials=30)  # Set to 30 trials\n",
        "\n",
        "    try:\n",
        "        trial = study.best_trial\n",
        "        print('Best trial:')\n",
        "        print('Value: {}'.format(trial.value))\n",
        "        print('Params: ')\n",
        "        for key, value in trial.params.items():\n",
        "            print('    {}: {}'.format(key, value))  # Print best trial parameters\n",
        "\n",
        "        logging.info('Best trial:')\n",
        "        logging.info('Value: {}'.format(trial.value))\n",
        "        logging.info('Params: ')\n",
        "        for key, value in trial.params.items():\n",
        "            logging.info('    {}: {}'.format(key, value))  # Log best trial parameters\n",
        "\n",
        "    except ValueError as e:\n",
        "        logging.error(f\"No completed trials: {e}\")  # Log error if no trials are completed\n",
        "\n",
        "    elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
        "    print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
        "    logging.info(f\"Elapsed time: {elapsed_time:.2f} seconds\")  # Log elapsed time\n",
        "\n",
        "# Run the optimization process\n",
        "if __name__ == '__main__':\n",
        "    run_optimization()  # Execute the optimization function\n",
        "\n"
      ],
      "metadata": {
        "id": "ho5wRWLDNvni",
        "outputId": "1ec4ec6d-9001-46b0-c1b1-9dbc33dcffa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting optimization for /content/EvoNet-CNN-Insight/model_training/Ancient_moderate/AM\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-04 13:36:59,143] A new study created in RDB with name: no-name-27a1444c-e844-4903-abb6-66718ee507fa\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 0 started with hyperparameters: num_layers=3, filters=[81, 126, 62], kernel_size=2, l1=0.003188315471455216, l2=2.1306421274251034e-06, dense_units=188, dropout_rate=0.2436894556788965, learning_rate=1.5036844388351935e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 78ms/step - accuracy: 0.5079 - loss: 10.6863 - val_accuracy: 0.4825 - val_loss: 10.5606\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5231 - loss: 10.5152 - val_accuracy: 0.4837 - val_loss: 10.3877\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5693 - loss: 10.3430 - val_accuracy: 0.4737 - val_loss: 10.2302\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5440 - loss: 10.1843 - val_accuracy: 0.6637 - val_loss: 10.0538\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5939 - loss: 10.0165 - val_accuracy: 0.6388 - val_loss: 9.8921\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5748 - loss: 9.8590 - val_accuracy: 0.5938 - val_loss: 9.7430\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5955 - loss: 9.7042 - val_accuracy: 0.4875 - val_loss: 9.6047\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5719 - loss: 9.5580 - val_accuracy: 0.5063 - val_loss: 9.4568\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6232 - loss: 9.4087 - val_accuracy: 0.6288 - val_loss: 9.3058\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6363 - loss: 9.3032\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-04 13:50:59,172] Trial 0 finished with value: 0.6274999976158142 and parameters: {'num_layers': 3, 'filters_0': 81, 'filters_1': 126, 'filters_2': 62, 'kernel_size': 2, 'l1': 0.003188315471455216, 'l2': 2.1306421274251034e-06, 'dense_units': 188, 'dropout_rate': 0.2436894556788965, 'learning_rate': 1.5036844388351935e-05}. Best is trial 0 with value: 0.6274999976158142.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 1 started with hyperparameters: num_layers=6, filters=[40, 67, 92, 32, 34, 55], kernel_size=2, l1=0.0037157522547798024, l2=0.00031460442046373686, dense_units=118, dropout_rate=0.14421927289369652, learning_rate=0.00013405854266477086\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 79ms/step - accuracy: 0.4940 - loss: 12.7731 - val_accuracy: 0.5525 - val_loss: 11.7009\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5104 - loss: 11.3581 - val_accuracy: 0.4800 - val_loss: 10.3526\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5312 - loss: 10.0321 - val_accuracy: 0.5788 - val_loss: 9.0940\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5342 - loss: 8.7961 - val_accuracy: 0.4938 - val_loss: 7.9261\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5083 - loss: 7.6502 - val_accuracy: 0.5625 - val_loss: 6.8469\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5419 - loss: 6.5936 - val_accuracy: 0.5050 - val_loss: 5.8570\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4843 - loss: 5.6266 - val_accuracy: 0.4663 - val_loss: 4.9583\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5091 - loss: 4.7498 - val_accuracy: 0.4787 - val_loss: 4.1501\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5066 - loss: 3.9641 - val_accuracy: 0.5025 - val_loss: 3.4313\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4971 - loss: 3.4314\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-04 14:04:55,833] Trial 1 finished with value: 0.5 and parameters: {'num_layers': 6, 'filters_0': 40, 'filters_1': 67, 'filters_2': 92, 'filters_3': 32, 'filters_4': 34, 'filters_5': 55, 'kernel_size': 2, 'l1': 0.0037157522547798024, 'l2': 0.00031460442046373686, 'dense_units': 118, 'dropout_rate': 0.14421927289369652, 'learning_rate': 0.00013405854266477086}. Best is trial 0 with value: 0.6274999976158142.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 started with hyperparameters: num_layers=6, filters=[77, 62, 62, 79, 43, 124], kernel_size=2, l1=0.003958400261066714, l2=0.0003186028997127795, dense_units=157, dropout_rate=0.48430149187312244, learning_rate=0.00015127304327059845\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.4939 - loss: 18.4527 - val_accuracy: 0.5175 - val_loss: 16.5284\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5083 - loss: 15.9188 - val_accuracy: 0.4800 - val_loss: 14.1414\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5150 - loss: 13.5804 - val_accuracy: 0.5375 - val_loss: 11.9488\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5075 - loss: 11.4364 - val_accuracy: 0.4938 - val_loss: 9.9523\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5070 - loss: 9.4895 - val_accuracy: 0.4913 - val_loss: 8.1535\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5176 - loss: 7.7398 - val_accuracy: 0.5050 - val_loss: 6.5524\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4949 - loss: 6.1887 - val_accuracy: 0.4663 - val_loss: 5.1492\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5122 - loss: 4.8335 - val_accuracy: 0.4787 - val_loss: 3.9406\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5016 - loss: 3.6742 - val_accuracy: 0.5025 - val_loss: 2.9285\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4971 - loss: 2.9285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 14:18:54,415] Trial 2 finished with value: 0.5 and parameters: {'num_layers': 6, 'filters_0': 77, 'filters_1': 62, 'filters_2': 62, 'filters_3': 79, 'filters_4': 43, 'filters_5': 124, 'kernel_size': 2, 'l1': 0.003958400261066714, 'l2': 0.0003186028997127795, 'dense_units': 157, 'dropout_rate': 0.48430149187312244, 'learning_rate': 0.00015127304327059845}. Best is trial 0 with value: 0.6274999976158142.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 started with hyperparameters: num_layers=6, filters=[118, 72, 39, 63, 46, 37], kernel_size=2, l1=0.001534374491080392, l2=6.500453737357206e-05, dense_units=255, dropout_rate=0.4154533737909599, learning_rate=0.00010622693936776803\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step - accuracy: 0.4935 - loss: 6.5923 - val_accuracy: 0.4825 - val_loss: 6.1555\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5014 - loss: 6.0147 - val_accuracy: 0.4800 - val_loss: 5.5999\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5276 - loss: 5.4664 - val_accuracy: 0.5888 - val_loss: 5.0741\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4979 - loss: 4.9485 - val_accuracy: 0.4938 - val_loss: 4.5791\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5019 - loss: 4.4611 - val_accuracy: 0.4913 - val_loss: 4.1151\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5021 - loss: 4.0046 - val_accuracy: 0.5050 - val_loss: 3.6813\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4943 - loss: 3.5787 - val_accuracy: 0.4663 - val_loss: 3.2789\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5091 - loss: 3.1834 - val_accuracy: 0.4787 - val_loss: 2.9068\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5066 - loss: 2.8192 - val_accuracy: 0.5025 - val_loss: 2.5654\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4971 - loss: 2.5654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 14:32:56,098] Trial 3 finished with value: 0.5 and parameters: {'num_layers': 6, 'filters_0': 118, 'filters_1': 72, 'filters_2': 39, 'filters_3': 63, 'filters_4': 46, 'filters_5': 37, 'kernel_size': 2, 'l1': 0.001534374491080392, 'l2': 6.500453737357206e-05, 'dense_units': 255, 'dropout_rate': 0.4154533737909599, 'learning_rate': 0.00010622693936776803}. Best is trial 0 with value: 0.6274999976158142.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 4 started with hyperparameters: num_layers=5, filters=[65, 95, 120, 104, 101], kernel_size=2, l1=0.00103874997171825, l2=0.003585611973094507, dense_units=171, dropout_rate=0.4318525854836528, learning_rate=1.9115119201249632e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 84ms/step - accuracy: 0.4792 - loss: 9.3046 - val_accuracy: 0.5450 - val_loss: 9.1530\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5145 - loss: 9.1041 - val_accuracy: 0.6463 - val_loss: 8.9553\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5258 - loss: 8.9066 - val_accuracy: 0.5650 - val_loss: 8.7612\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5349 - loss: 8.7138 - val_accuracy: 0.5875 - val_loss: 8.5697\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5534 - loss: 8.5234 - val_accuracy: 0.5962 - val_loss: 8.3817\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5824 - loss: 8.3371 - val_accuracy: 0.5550 - val_loss: 8.2007\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5600 - loss: 8.1565 - val_accuracy: 0.5775 - val_loss: 8.0220\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5744 - loss: 7.9793 - val_accuracy: 0.4775 - val_loss: 7.8526\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5675 - loss: 7.8057 - val_accuracy: 0.6463 - val_loss: 7.6782\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6530 - loss: 7.6780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 14:46:55,402] Trial 4 finished with value: 0.6389999985694885 and parameters: {'num_layers': 5, 'filters_0': 65, 'filters_1': 95, 'filters_2': 120, 'filters_3': 104, 'filters_4': 101, 'kernel_size': 2, 'l1': 0.00103874997171825, 'l2': 0.003585611973094507, 'dense_units': 171, 'dropout_rate': 0.4318525854836528, 'learning_rate': 1.9115119201249632e-05}. Best is trial 4 with value: 0.6389999985694885.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 started with hyperparameters: num_layers=4, filters=[32, 75, 109, 83], kernel_size=3, l1=1.7174083354864713e-06, l2=1.6235738704898867e-06, dense_units=102, dropout_rate=0.3722838137130191, learning_rate=1.3704829496890478e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5141 - loss: 0.7035"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 14:48:27,825] Trial 5 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 6 started with hyperparameters: num_layers=6, filters=[40, 52, 125, 59, 36, 42], kernel_size=2, l1=0.0012471121629317858, l2=1.1542106152288147e-06, dense_units=133, dropout_rate=0.15469546050015587, learning_rate=1.785515750822334e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4808 - loss: 5.6884"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 14:50:00,110] Trial 6 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 7 started with hyperparameters: num_layers=4, filters=[79, 69, 104, 89], kernel_size=3, l1=1.1549867023508182e-05, l2=2.9234074338265126e-05, dense_units=96, dropout_rate=0.3019275105860717, learning_rate=0.0006964148965314465\n",
            "\u001b[1m48/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5156 - loss: 0.7742"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 14:51:33,213] Trial 7 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 8 started with hyperparameters: num_layers=3, filters=[57, 55, 43], kernel_size=3, l1=0.00010204311744386488, l2=0.004730244459370741, dense_units=126, dropout_rate=0.4543217794285237, learning_rate=0.00021630608280942364\n",
            "\u001b[1m48/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5044 - loss: 1.3987"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 14:53:03,138] Trial 8 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 9 started with hyperparameters: num_layers=6, filters=[110, 76, 87, 101, 110, 39], kernel_size=2, l1=1.2752803740715663e-06, l2=0.0027534046869533086, dense_units=158, dropout_rate=0.29558210452988243, learning_rate=9.10835088637428e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5004 - loss: 1.8489"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 14:54:37,276] Trial 9 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 started with hyperparameters: num_layers=5, filters=[98, 101, 126, 125, 106], kernel_size=3, l1=0.0001599413926484347, l2=0.0010965164795917188, dense_units=216, dropout_rate=0.36900493496534537, learning_rate=3.643917147482404e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4922 - loss: 3.1665"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 14:56:15,021] Trial 10 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 11 started with hyperparameters: num_layers=3, filters=[68, 126, 68], kernel_size=2, l1=0.0003308573272589914, l2=1.3485469414617025e-05, dense_units=198, dropout_rate=0.232537744438069, learning_rate=3.3205390538656154e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5085 - loss: 1.6920"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 14:57:46,008] Trial 11 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 12 started with hyperparameters: num_layers=5, filters=[95, 101, 63, 124, 85], kernel_size=2, l1=0.008830956777448488, l2=7.077152855435928e-06, dense_units=194, dropout_rate=0.21628666426711396, learning_rate=1.1550623069727768e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 91ms/step - accuracy: 0.5056 - loss: 54.3981 - val_accuracy: 0.5462 - val_loss: 53.8731\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5358 - loss: 53.6987 - val_accuracy: 0.5700 - val_loss: 53.1786\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4990 - loss: 53.0065 - val_accuracy: 0.4737 - val_loss: 52.4892\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5051 - loss: 52.3178 - val_accuracy: 0.5663 - val_loss: 51.8028\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5367 - loss: 51.6329 - val_accuracy: 0.5950 - val_loss: 51.1218\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5365 - loss: 50.9537 - val_accuracy: 0.6413 - val_loss: 50.4462\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5409 - loss: 50.2785 - val_accuracy: 0.6450 - val_loss: 49.7751\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5643 - loss: 49.6081 - val_accuracy: 0.5938 - val_loss: 49.1086\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5720 - loss: 48.9426 - val_accuracy: 0.6388 - val_loss: 48.4464\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6420 - loss: 48.4464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 15:11:47,305] Trial 12 finished with value: 0.6342499852180481 and parameters: {'num_layers': 5, 'filters_0': 95, 'filters_1': 101, 'filters_2': 63, 'filters_3': 124, 'filters_4': 85, 'kernel_size': 2, 'l1': 0.008830956777448488, 'l2': 7.077152855435928e-06, 'dense_units': 194, 'dropout_rate': 0.21628666426711396, 'learning_rate': 1.1550623069727768e-05}. Best is trial 4 with value: 0.6389999985694885.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 13 started with hyperparameters: num_layers=5, filters=[95, 97, 73, 128, 83], kernel_size=2, l1=0.00892468005694892, l2=8.142231605430539e-06, dense_units=230, dropout_rate=0.21725357886635532, learning_rate=3.1536924417588204e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 83ms/step - accuracy: 0.5061 - loss: 57.2015 - val_accuracy: 0.5175 - val_loss: 55.6821\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5187 - loss: 55.1826 - val_accuracy: 0.5725 - val_loss: 53.6917\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5368 - loss: 53.2013 - val_accuracy: 0.5788 - val_loss: 51.7387\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5492 - loss: 51.2578 - val_accuracy: 0.5987 - val_loss: 49.8222\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5756 - loss: 49.3507 - val_accuracy: 0.5875 - val_loss: 47.9434\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5737 - loss: 47.4831 - val_accuracy: 0.5587 - val_loss: 46.1056\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5502 - loss: 45.6536 - val_accuracy: 0.6350 - val_loss: 44.3054\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.6045 - loss: 43.8637 - val_accuracy: 0.5387 - val_loss: 42.5465\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5641 - loss: 42.1123 - val_accuracy: 0.6000 - val_loss: 40.8233\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6020 - loss: 40.8233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 15:25:48,942] Trial 13 finished with value: 0.5912500023841858 and parameters: {'num_layers': 5, 'filters_0': 95, 'filters_1': 97, 'filters_2': 73, 'filters_3': 128, 'filters_4': 83, 'kernel_size': 2, 'l1': 0.00892468005694892, 'l2': 8.142231605430539e-06, 'dense_units': 230, 'dropout_rate': 0.21725357886635532, 'learning_rate': 3.1536924417588204e-05}. Best is trial 4 with value: 0.6389999985694885.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 14 started with hyperparameters: num_layers=5, filters=[57, 96, 53, 110, 83], kernel_size=2, l1=0.00075849685136056, l2=0.00022087313484647766, dense_units=182, dropout_rate=0.10073471109174587, learning_rate=1.0573664593952088e-05\n",
            "\u001b[1m48/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5087 - loss: 4.4363"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 15:27:21,571] Trial 14 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 15 started with hyperparameters: num_layers=4, filters=[127, 111, 105, 110], kernel_size=2, l1=3.211516161635561e-05, l2=6.984180282618145e-06, dense_units=65, dropout_rate=0.30612398892409953, learning_rate=2.2503335389457226e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5084 - loss: 0.8919"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 15:28:54,890] Trial 15 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 16 started with hyperparameters: num_layers=5, filters=[95, 89, 80, 113, 96], kernel_size=2, l1=0.009668548682355706, l2=0.009865192175372252, dense_units=170, dropout_rate=0.36470345180988695, learning_rate=6.265350841857398e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 83ms/step - accuracy: 0.5077 - loss: 64.4831 - val_accuracy: 0.5175 - val_loss: 61.0416\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5152 - loss: 59.9270 - val_accuracy: 0.5650 - val_loss: 56.6261\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5423 - loss: 55.5567 - val_accuracy: 0.5325 - val_loss: 52.3954\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5482 - loss: 51.3727 - val_accuracy: 0.4938 - val_loss: 48.3513\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5274 - loss: 47.3754 - val_accuracy: 0.5612 - val_loss: 44.4929\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5490 - loss: 43.5623 - val_accuracy: 0.5312 - val_loss: 40.8150\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5096 - loss: 39.9289 - val_accuracy: 0.4663 - val_loss: 37.3145\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5113 - loss: 36.4708 - val_accuracy: 0.4787 - val_loss: 33.9890\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5232 - loss: 33.1899 - val_accuracy: 0.5025 - val_loss: 30.8384\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4971 - loss: 30.8384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 15:42:55,185] Trial 16 finished with value: 0.5 and parameters: {'num_layers': 5, 'filters_0': 95, 'filters_1': 89, 'filters_2': 80, 'filters_3': 113, 'filters_4': 96, 'kernel_size': 2, 'l1': 0.009668548682355706, 'l2': 0.009865192175372252, 'dense_units': 170, 'dropout_rate': 0.36470345180988695, 'learning_rate': 6.265350841857398e-05}. Best is trial 4 with value: 0.6389999985694885.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 17 started with hyperparameters: num_layers=5, filters=[62, 112, 51, 97, 128], kernel_size=3, l1=0.000570101925543305, l2=0.0010735580924276283, dense_units=212, dropout_rate=0.20062391619066527, learning_rate=5.4847242841985824e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5094 - loss: 5.5744"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 15:44:29,308] Trial 17 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 18 started with hyperparameters: num_layers=4, filters=[104, 35, 115, 123], kernel_size=2, l1=2.9695529012456717e-05, l2=6.983831542646024e-05, dense_units=245, dropout_rate=0.41709795573233444, learning_rate=0.0003276474463433371\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5148 - loss: 0.8203"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 15:46:00,916] Trial 18 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 19 started with hyperparameters: num_layers=5, filters=[85, 111, 94, 99, 62], kernel_size=2, l1=0.0002618665877402687, l2=3.7206804019467463e-06, dense_units=150, dropout_rate=0.27685788141540424, learning_rate=1.1138582085029436e-05\n",
            "\u001b[1m48/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5073 - loss: 2.3380"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 15:47:34,280] Trial 19 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 started with hyperparameters: num_layers=4, filters=[68, 83, 79, 117], kernel_size=3, l1=0.0019212456916767415, l2=2.3414616620659253e-05, dense_units=201, dropout_rate=0.3321293019441081, learning_rate=5.41989259219258e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5014 - loss: 12.0592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 15:49:07,830] Trial 20 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 21 started with hyperparameters: num_layers=3, filters=[86, 128, 58], kernel_size=2, l1=0.003834468328454987, l2=2.725994196005307e-06, dense_units=189, dropout_rate=0.24093038190013383, learning_rate=1.872399855279294e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5051 - loss: 12.8444"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 15:50:39,212] Trial 21 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 22 started with hyperparameters: num_layers=5, filters=[73, 120, 66, 69, 67], kernel_size=2, l1=0.0029332959431420834, l2=3.4303281520413827e-06, dense_units=175, dropout_rate=0.17691795638839813, learning_rate=2.3474626056974196e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 84ms/step - accuracy: 0.4976 - loss: 15.0220 - val_accuracy: 0.5213 - val_loss: 14.7579\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5102 - loss: 14.6718 - val_accuracy: 0.5700 - val_loss: 14.4105\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5324 - loss: 14.3250 - val_accuracy: 0.4963 - val_loss: 14.0693\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5227 - loss: 13.9844 - val_accuracy: 0.6612 - val_loss: 13.7300\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5720 - loss: 13.6467 - val_accuracy: 0.5638 - val_loss: 13.3963\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5653 - loss: 13.3151 - val_accuracy: 0.5437 - val_loss: 13.0693\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5367 - loss: 12.9885 - val_accuracy: 0.5962 - val_loss: 12.7464\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6033 - loss: 12.6680 - val_accuracy: 0.5487 - val_loss: 12.4314\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5566 - loss: 12.3526 - val_accuracy: 0.6263 - val_loss: 12.1192\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6301 - loss: 12.1191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 16:04:38,800] Trial 22 finished with value: 0.6140000224113464 and parameters: {'num_layers': 5, 'filters_0': 73, 'filters_1': 120, 'filters_2': 66, 'filters_3': 69, 'filters_4': 67, 'kernel_size': 2, 'l1': 0.0029332959431420834, 'l2': 3.4303281520413827e-06, 'dense_units': 175, 'dropout_rate': 0.17691795638839813, 'learning_rate': 2.3474626056974196e-05}. Best is trial 4 with value: 0.6389999985694885.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 23 started with hyperparameters: num_layers=3, filters=[91, 88, 51], kernel_size=2, l1=0.00934936717475122, l2=3.2639609383735656e-05, dense_units=223, dropout_rate=0.2625384443371469, learning_rate=1.439427426743653e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 74ms/step - accuracy: 0.5226 - loss: 23.1136 - val_accuracy: 0.4825 - val_loss: 22.8613\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5305 - loss: 22.7765 - val_accuracy: 0.5750 - val_loss: 22.5227\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5598 - loss: 22.4405 - val_accuracy: 0.5013 - val_loss: 22.2001\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5595 - loss: 22.1154 - val_accuracy: 0.6700 - val_loss: 21.8635\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5927 - loss: 21.7852 - val_accuracy: 0.6850 - val_loss: 21.5385\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5811 - loss: 21.4656 - val_accuracy: 0.6025 - val_loss: 21.2294\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5859 - loss: 21.1511 - val_accuracy: 0.5337 - val_loss: 20.9272\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5660 - loss: 20.8493 - val_accuracy: 0.5063 - val_loss: 20.6288\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6208 - loss: 20.5409 - val_accuracy: 0.6500 - val_loss: 20.3211\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6470 - loss: 20.3200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 16:18:39,804] Trial 23 finished with value: 0.6399999856948853 and parameters: {'num_layers': 3, 'filters_0': 91, 'filters_1': 88, 'filters_2': 51, 'kernel_size': 2, 'l1': 0.00934936717475122, 'l2': 3.2639609383735656e-05, 'dense_units': 223, 'dropout_rate': 0.2625384443371469, 'learning_rate': 1.439427426743653e-05}. Best is trial 23 with value: 0.6399999856948853.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 24 started with hyperparameters: num_layers=4, filters=[90, 85, 48, 104], kernel_size=2, l1=0.007831178580633874, l2=3.31883772109201e-05, dense_units=232, dropout_rate=0.26712490397461175, learning_rate=1.003207843005365e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.5150 - loss: 26.4893 - val_accuracy: 0.5213 - val_loss: 26.2901\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5317 - loss: 26.2255 - val_accuracy: 0.5838 - val_loss: 26.0276\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5589 - loss: 25.9626 - val_accuracy: 0.6075 - val_loss: 25.7674\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5587 - loss: 25.7028 - val_accuracy: 0.5975 - val_loss: 25.5075\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5624 - loss: 25.4450 - val_accuracy: 0.5987 - val_loss: 25.2482\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5744 - loss: 25.1874 - val_accuracy: 0.5650 - val_loss: 24.9961\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5692 - loss: 24.9320 - val_accuracy: 0.5975 - val_loss: 24.7415\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5759 - loss: 24.6829 - val_accuracy: 0.5038 - val_loss: 24.4998\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5520 - loss: 24.4337 - val_accuracy: 0.5850 - val_loss: 24.2481\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6010 - loss: 24.2480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 16:32:40,524] Trial 24 finished with value: 0.5842499732971191 and parameters: {'num_layers': 4, 'filters_0': 90, 'filters_1': 85, 'filters_2': 48, 'filters_3': 104, 'kernel_size': 2, 'l1': 0.007831178580633874, 'l2': 3.31883772109201e-05, 'dense_units': 232, 'dropout_rate': 0.26712490397461175, 'learning_rate': 1.003207843005365e-05}. Best is trial 23 with value: 0.6399999856948853.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 25 started with hyperparameters: num_layers=5, filters=[107, 104, 42, 92, 97], kernel_size=2, l1=0.0007392638475217043, l2=0.00016602614868016817, dense_units=219, dropout_rate=0.1898362697995375, learning_rate=2.5239482501681245e-05\n",
            "\u001b[1m48/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5012 - loss: 4.5723"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 16:34:14,494] Trial 25 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 26 started with hyperparameters: num_layers=4, filters=[50, 91, 73, 118], kernel_size=2, l1=0.0059151443315403895, l2=1.1259329056013594e-05, dense_units=142, dropout_rate=0.33221970808788714, learning_rate=1.6120646535662953e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.5194 - loss: 22.7581 - val_accuracy: 0.5188 - val_loss: 22.4741\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5204 - loss: 22.3820 - val_accuracy: 0.5462 - val_loss: 22.0998\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5582 - loss: 22.0091 - val_accuracy: 0.6500 - val_loss: 21.7314\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5736 - loss: 21.6406 - val_accuracy: 0.6237 - val_loss: 21.3652\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5985 - loss: 21.2757 - val_accuracy: 0.6037 - val_loss: 21.0023\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5805 - loss: 20.9165 - val_accuracy: 0.5587 - val_loss: 20.6510\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5679 - loss: 20.5628 - val_accuracy: 0.5975 - val_loss: 20.2992\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5885 - loss: 20.2158 - val_accuracy: 0.4863 - val_loss: 19.9646\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5737 - loss: 19.8731 - val_accuracy: 0.6538 - val_loss: 19.6178\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6701 - loss: 19.6170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 16:48:23,971] Trial 26 finished with value: 0.6527500152587891 and parameters: {'num_layers': 4, 'filters_0': 50, 'filters_1': 91, 'filters_2': 73, 'filters_3': 118, 'kernel_size': 2, 'l1': 0.0059151443315403895, 'l2': 1.1259329056013594e-05, 'dense_units': 142, 'dropout_rate': 0.33221970808788714, 'learning_rate': 1.6120646535662953e-05}. Best is trial 26 with value: 0.6527500152587891.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 27 started with hyperparameters: num_layers=3, filters=[51, 88, 86], kernel_size=2, l1=0.0010875382155268918, l2=9.746038405939761e-05, dense_units=140, dropout_rate=0.33068795393329103, learning_rate=4.340551521299577e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5078 - loss: 3.2564"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 16:49:57,776] Trial 27 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 28 started with hyperparameters: num_layers=3, filters=[46, 92, 36], kernel_size=2, l1=0.00036418951140005474, l2=0.0005864989581047493, dense_units=108, dropout_rate=0.3962471352461145, learning_rate=1.8836662706717208e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4937 - loss: 1.3457"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 16:51:27,699] Trial 28 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 29 started with hyperparameters: num_layers=3, filters=[64, 80, 75], kernel_size=2, l1=0.0027201470819170626, l2=1.4516792008647347e-05, dense_units=148, dropout_rate=0.43655419335065637, learning_rate=1.4983611953051604e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5113 - loss: 6.8007"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 16:52:57,506] Trial 29 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            "Value: 0.6527500152587891\n",
            "Params: \n",
            "    num_layers: 4\n",
            "    filters_0: 50\n",
            "    filters_1: 91\n",
            "    filters_2: 73\n",
            "    filters_3: 118\n",
            "    kernel_size: 2\n",
            "    l1: 0.0059151443315403895\n",
            "    l2: 1.1259329056013594e-05\n",
            "    dense_units: 142\n",
            "    dropout_rate: 0.33221970808788714\n",
            "    learning_rate: 1.6120646535662953e-05\n",
            "Elapsed time: 11758.62 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ok3mgEDI3hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, regularizers, callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "import time\n",
        "import gzip\n",
        "import skimage.transform\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "\n",
        "# Configure logging to file in the current directory with the specified name\n",
        "logging.basicConfig(filename='Ancient_Scenarios_AS.log', level=logging.INFO,\n",
        "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
        "\n",
        "# Function to preprocess data\n",
        "def preprocess_data(simulations_folder, batch_number):\n",
        "    # Create ImaFile object for the specified simulation folder and model\n",
        "    file_sim = ImaFile(simulations_folder=os.path.join(simulations_folder, f'Simulations{batch_number}'), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "\n",
        "    # Read the simulation data\n",
        "    gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=4000)\n",
        "\n",
        "    # Filter simulations based on frequency threshold\n",
        "    gene_sim.filter_freq(0.01)\n",
        "\n",
        "    # Sort simulations by row frequency\n",
        "    gene_sim.sort('rows_freq')\n",
        "\n",
        "    # Resize simulation data to the required dimensions\n",
        "    gene_sim.resize((198, 192))\n",
        "\n",
        "    # Convert simulation data (flip=True allows for data augmentation)\n",
        "    gene_sim.convert(flip=True)\n",
        "\n",
        "    # Get a random subset of indices and subset the simulation data\n",
        "    gene_sim.subset(get_index_random(gene_sim))\n",
        "\n",
        "    # Convert targets to binary format\n",
        "    gene_sim.targets = to_binary(gene_sim.targets)\n",
        "\n",
        "    return gene_sim\n",
        "\n",
        "# Objective function for Optuna optimization\n",
        "def objective(trial, simulations_folder, epochs=1):\n",
        "    # Set random seed\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    # Hyperparameters to be optimized\n",
        "    num_layers = trial.suggest_int('num_layers', 3, 6)  # Limit the number of layers to avoid excessive reduction\n",
        "    filters = [trial.suggest_int(f'filters_{i}', 32, 128) for i in range(num_layers)]  # Adjust filters range\n",
        "    kernel_size = trial.suggest_int('kernel_size', 2, 3)  # Limit the kernel size to avoid excessive reduction\n",
        "    l1 = trial.suggest_float('l1', 1e-6, 1e-2, log=True)\n",
        "    l2 = trial.suggest_float('l2', 1e-6, 1e-2, log=True)\n",
        "    dense_units = trial.suggest_int('dense_units', 64, 256)  # Adjust dense units range\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
        "\n",
        "    # Log the hyperparameters at the start of each trial\n",
        "    logging.info(f'Trial {trial.number} started with hyperparameters: num_layers={num_layers}, filters={filters}, '\n",
        "                 f'kernel_size={kernel_size}, l1={l1}, l2={l2}, dense_units={dense_units}, '\n",
        "                 f'dropout_rate={dropout_rate}, learning_rate={learning_rate}')\n",
        "    print(f'Trial {trial.number} started with hyperparameters: num_layers={num_layers}, filters={filters}, '\n",
        "          f'kernel_size={kernel_size}, l1={l1}, l2={l2}, dense_units={dense_units}, '\n",
        "          f'dropout_rate={dropout_rate}, learning_rate={learning_rate}')\n",
        "\n",
        "    # Building the model based on sampled hyperparameters\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=(198, 192, 1)))  # Define the input layer\n",
        "    for i in range(num_layers):\n",
        "        model.add(layers.Conv2D(filters=filters[i], kernel_size=(kernel_size, kernel_size), strides=(1, 1), activation='relu',\n",
        "                                kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2), padding='same'))  # Use 'same' padding to avoid dimension issues\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())  # Flatten the output for the Dense layers\n",
        "    model.add(layers.Dense(units=dense_units, activation='relu'))  # Add Dense layer\n",
        "    model.add(layers.Dropout(rate=dropout_rate))  # Add Dropout layer\n",
        "    model.add(layers.Dense(units=1, activation='sigmoid'))  # Output layer with sigmoid activation\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)  # Define optimizer\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])  # Compile the model\n",
        "\n",
        "    # Pruning callback to terminate unpromising trials\n",
        "    pruning_callback = TFKerasPruningCallback(trial, 'val_loss')\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Incremental training on 9 batches\n",
        "    best_val_loss = np.inf  # Track the best validation loss\n",
        "    for batch_number in range(1, 10):\n",
        "        gene_sim = preprocess_data(simulations_folder, batch_number)  # Preprocess data\n",
        "        history = model.fit(gene_sim.data, gene_sim.targets, batch_size=64, epochs=epochs, verbose=1, validation_split=0.2,\n",
        "                            callbacks=[early_stopping, pruning_callback])  # Train the model with callbacks\n",
        "\n",
        "        # Get the validation loss for the current epoch\n",
        "        val_loss = min(history.history['val_loss'])\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            trial.report(val_loss, batch_number)\n",
        "            if trial.should_prune():\n",
        "                raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    # Evaluate the model on the 10th batch\n",
        "    gene_sim = preprocess_data(simulations_folder, 10)\n",
        "    evaluation = model.evaluate(gene_sim.data, gene_sim.targets, verbose=1)\n",
        "    return evaluation[1]  # Return the accuracy\n",
        "\n",
        "# Function to run the optimization process\n",
        "def run_optimization():\n",
        "    start_time = time.time()  # Record start time\n",
        "\n",
        "    simulations_folder = '/content/EvoNet-CNN-Insight/model_training/Ancient_strong/AS'  # Folder for this dataset\n",
        "    logging.info(f\"Starting optimization for {simulations_folder}\")\n",
        "    print(f\"Starting optimization for {simulations_folder}\")\n",
        "\n",
        "    # Create an Optuna study and optimize the objective function\n",
        "    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner(), storage='sqlite:///as_study.db', load_if_exists=True)  # Use SQLite storage\n",
        "    study.optimize(lambda trial: objective(trial, simulations_folder), n_trials=30)  # Set to 30 trials\n",
        "\n",
        "    try:\n",
        "        trial = study.best_trial\n",
        "        print('Best trial:')\n",
        "        print('Value: {}'.format(trial.value))\n",
        "        print('Params: ')\n",
        "        for key, value in trial.params.items():\n",
        "            print('    {}: {}'.format(key, value))  # Print best trial parameters\n",
        "\n",
        "        logging.info('Best trial:')\n",
        "        logging.info('Value: {}'.format(trial.value))\n",
        "        logging.info('Params: ')\n",
        "        for key, value in trial.params.items():\n",
        "            logging.info('    {}: {}'.format(key, value))  # Log best trial parameters\n",
        "\n",
        "    except ValueError as e:\n",
        "        logging.error(f\"No completed trials: {e}\")  # Log error if no trials are completed\n",
        "\n",
        "    elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
        "    print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
        "    logging.info(f\"Elapsed time: {elapsed_time:.2f} seconds\")  # Log elapsed time\n",
        "\n",
        "# Run the optimization process\n",
        "if __name__ == '__main__':\n",
        "    run_optimization()  # Execute the optimization function\n"
      ],
      "metadata": {
        "id": "ToN8-2PNI4At",
        "outputId": "9adaf18a-b89b-426d-f84d-086291113580",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting optimization for /content/EvoNet-CNN-Insight/model_training/Ancient_strong/AS\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-04 16:53:47,831] A new study created in RDB with name: no-name-067d7dc7-68ad-43ea-b254-8bbaa3d81a1b\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 0 started with hyperparameters: num_layers=4, filters=[88, 38, 88, 106], kernel_size=3, l1=1.5022150089120748e-05, l2=0.0035801025371631446, dense_units=193, dropout_rate=0.2866844238417743, learning_rate=0.00016920857191232494\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.4980 - loss: 1.4448 - val_accuracy: 0.5175 - val_loss: 1.2840\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5155 - loss: 1.2405 - val_accuracy: 0.5200 - val_loss: 1.1213\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5080 - loss: 1.0901 - val_accuracy: 0.4888 - val_loss: 1.0035\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5203 - loss: 0.9798 - val_accuracy: 0.5813 - val_loss: 0.9162\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5418 - loss: 0.8997 - val_accuracy: 0.5100 - val_loss: 0.8571\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5257 - loss: 0.8457 - val_accuracy: 0.5050 - val_loss: 0.8200\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5750 - loss: 0.7936 - val_accuracy: 0.5875 - val_loss: 0.7658\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5728 - loss: 0.7611 - val_accuracy: 0.6250 - val_loss: 0.7311\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6284 - loss: 0.7155 - val_accuracy: 0.6375 - val_loss: 0.7022\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6490 - loss: 0.6942\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-04 17:08:01,942] Trial 0 finished with value: 0.6507499814033508 and parameters: {'num_layers': 4, 'filters_0': 88, 'filters_1': 38, 'filters_2': 88, 'filters_3': 106, 'kernel_size': 3, 'l1': 1.5022150089120748e-05, 'l2': 0.0035801025371631446, 'dense_units': 193, 'dropout_rate': 0.2866844238417743, 'learning_rate': 0.00016920857191232494}. Best is trial 0 with value: 0.6507499814033508.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 1 started with hyperparameters: num_layers=5, filters=[121, 83, 93, 35, 127], kernel_size=2, l1=8.57767954844711e-06, l2=0.0018156400922245438, dense_units=162, dropout_rate=0.43753306747558995, learning_rate=1.4487334426505518e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.5112 - loss: 1.2640 - val_accuracy: 0.5288 - val_loss: 1.2556\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.4991 - loss: 1.2534 - val_accuracy: 0.4800 - val_loss: 1.2456\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.4995 - loss: 1.2433 - val_accuracy: 0.4875 - val_loss: 1.2350\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5220 - loss: 1.2323 - val_accuracy: 0.5125 - val_loss: 1.2247\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5141 - loss: 1.2222 - val_accuracy: 0.5163 - val_loss: 1.2148\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5341 - loss: 1.2124 - val_accuracy: 0.5200 - val_loss: 1.2053\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5155 - loss: 1.2031 - val_accuracy: 0.5150 - val_loss: 1.1959\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5175 - loss: 1.1939 - val_accuracy: 0.6037 - val_loss: 1.1865\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5309 - loss: 1.1841 - val_accuracy: 0.5975 - val_loss: 1.1772\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6031 - loss: 1.1770\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-04 17:22:29,124] Trial 1 finished with value: 0.6042500138282776 and parameters: {'num_layers': 5, 'filters_0': 121, 'filters_1': 83, 'filters_2': 93, 'filters_3': 35, 'filters_4': 127, 'kernel_size': 2, 'l1': 8.57767954844711e-06, 'l2': 0.0018156400922245438, 'dense_units': 162, 'dropout_rate': 0.43753306747558995, 'learning_rate': 1.4487334426505518e-05}. Best is trial 0 with value: 0.6507499814033508.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 2 started with hyperparameters: num_layers=5, filters=[127, 50, 117, 44, 107], kernel_size=2, l1=0.0016065992182362483, l2=4.475662058253424e-06, dense_units=100, dropout_rate=0.3325663252391241, learning_rate=4.8068198908046e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.5083 - loss: 7.4071 - val_accuracy: 0.5175 - val_loss: 7.1565\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5092 - loss: 7.0754 - val_accuracy: 0.5288 - val_loss: 6.8312\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5144 - loss: 6.7511 - val_accuracy: 0.4725 - val_loss: 6.5137\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5013 - loss: 6.4357 - val_accuracy: 0.5100 - val_loss: 6.2039\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5123 - loss: 6.1282 - val_accuracy: 0.5125 - val_loss: 5.9028\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5244 - loss: 5.8291 - val_accuracy: 0.5050 - val_loss: 5.6103\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5061 - loss: 5.5390 - val_accuracy: 0.4663 - val_loss: 5.3266\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5058 - loss: 5.2572 - val_accuracy: 0.4787 - val_loss: 5.0511\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5296 - loss: 4.9835 - val_accuracy: 0.5025 - val_loss: 4.7837\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4971 - loss: 4.7838\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-04 17:36:44,192] Trial 2 finished with value: 0.5 and parameters: {'num_layers': 5, 'filters_0': 127, 'filters_1': 50, 'filters_2': 117, 'filters_3': 44, 'filters_4': 107, 'kernel_size': 2, 'l1': 0.0016065992182362483, 'l2': 4.475662058253424e-06, 'dense_units': 100, 'dropout_rate': 0.3325663252391241, 'learning_rate': 4.8068198908046e-05}. Best is trial 0 with value: 0.6507499814033508.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 3 started with hyperparameters: num_layers=5, filters=[110, 38, 122, 64, 116], kernel_size=2, l1=1.7249234370956124e-06, l2=0.0006412900136628196, dense_units=82, dropout_rate=0.2348662865247278, learning_rate=0.0006829476287295161\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 77ms/step - accuracy: 0.4976 - loss: 0.8508 - val_accuracy: 0.5175 - val_loss: 0.7730\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5068 - loss: 0.7584 - val_accuracy: 0.4800 - val_loss: 0.7264\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5055 - loss: 0.7206 - val_accuracy: 0.4725 - val_loss: 0.7083\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4958 - loss: 0.7059 - val_accuracy: 0.5063 - val_loss: 0.7007\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4930 - loss: 0.6998 - val_accuracy: 0.5088 - val_loss: 0.6974\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4933 - loss: 0.6969 - val_accuracy: 0.5050 - val_loss: 0.6956\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4778 - loss: 0.6954 - val_accuracy: 0.4663 - val_loss: 0.6947\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5091 - loss: 0.6945 - val_accuracy: 0.4787 - val_loss: 0.6942\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5066 - loss: 0.6940 - val_accuracy: 0.5025 - val_loss: 0.6937\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4971 - loss: 0.6937\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-04 17:50:56,075] Trial 3 finished with value: 0.5 and parameters: {'num_layers': 5, 'filters_0': 110, 'filters_1': 38, 'filters_2': 122, 'filters_3': 64, 'filters_4': 116, 'kernel_size': 2, 'l1': 1.7249234370956124e-06, 'l2': 0.0006412900136628196, 'dense_units': 82, 'dropout_rate': 0.2348662865247278, 'learning_rate': 0.0006829476287295161}. Best is trial 0 with value: 0.6507499814033508.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 4 started with hyperparameters: num_layers=5, filters=[39, 88, 99, 45, 99], kernel_size=3, l1=0.0002015246722596806, l2=7.107814817245623e-06, dense_units=76, dropout_rate=0.1408388447731393, learning_rate=2.5814020296899426e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 83ms/step - accuracy: 0.4978 - loss: 1.9368 - val_accuracy: 0.5175 - val_loss: 1.9060\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5125 - loss: 1.8972 - val_accuracy: 0.5213 - val_loss: 1.8682\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5181 - loss: 1.8590 - val_accuracy: 0.5587 - val_loss: 1.8304\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5046 - loss: 1.8218 - val_accuracy: 0.4938 - val_loss: 1.7941\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5188 - loss: 1.7845 - val_accuracy: 0.5088 - val_loss: 1.7575\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5121 - loss: 1.7493 - val_accuracy: 0.4950 - val_loss: 1.7236\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5138 - loss: 1.7152 - val_accuracy: 0.6025 - val_loss: 1.6891\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5413 - loss: 1.6811 - val_accuracy: 0.4787 - val_loss: 1.6570\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5225 - loss: 1.6480 - val_accuracy: 0.5500 - val_loss: 1.6232\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5624 - loss: 1.6229\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-04 18:05:06,637] Trial 4 finished with value: 0.5647500157356262 and parameters: {'num_layers': 5, 'filters_0': 39, 'filters_1': 88, 'filters_2': 99, 'filters_3': 45, 'filters_4': 99, 'kernel_size': 3, 'l1': 0.0002015246722596806, 'l2': 7.107814817245623e-06, 'dense_units': 76, 'dropout_rate': 0.1408388447731393, 'learning_rate': 2.5814020296899426e-05}. Best is trial 0 with value: 0.6507499814033508.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 5 started with hyperparameters: num_layers=6, filters=[69, 83, 49, 46, 55, 113], kernel_size=2, l1=0.00010381470663759735, l2=0.006591678568082662, dense_units=219, dropout_rate=0.4474944648999233, learning_rate=0.0009371554544969989\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 88ms/step - accuracy: 0.4859 - loss: 2.5854 - val_accuracy: 0.5175 - val_loss: 1.3207\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4915 - loss: 1.1396 - val_accuracy: 0.4800 - val_loss: 0.8096\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4909 - loss: 0.7713 - val_accuracy: 0.4725 - val_loss: 0.7080\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5057 - loss: 0.7026 - val_accuracy: 0.4938 - val_loss: 0.6947\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4934 - loss: 0.6943 - val_accuracy: 0.4913 - val_loss: 0.6937\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4940 - loss: 0.6938 - val_accuracy: 0.5050 - val_loss: 0.6937\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4829 - loss: 0.6938 - val_accuracy: 0.4663 - val_loss: 0.6939\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4882 - loss: 0.6938 - val_accuracy: 0.4787 - val_loss: 0.6939\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5049 - loss: 0.6938 - val_accuracy: 0.5025 - val_loss: 0.6937\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4971 - loss: 0.6938\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-04 18:19:20,914] Trial 5 finished with value: 0.5 and parameters: {'num_layers': 6, 'filters_0': 69, 'filters_1': 83, 'filters_2': 49, 'filters_3': 46, 'filters_4': 55, 'filters_5': 113, 'kernel_size': 2, 'l1': 0.00010381470663759735, 'l2': 0.006591678568082662, 'dense_units': 219, 'dropout_rate': 0.4474944648999233, 'learning_rate': 0.0009371554544969989}. Best is trial 0 with value: 0.6507499814033508.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 6 started with hyperparameters: num_layers=6, filters=[81, 120, 116, 105, 59, 112], kernel_size=3, l1=0.006603823222315412, l2=0.002900513795476131, dense_units=146, dropout_rate=0.41997302492548794, learning_rate=0.0004072581667211054\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - accuracy: 0.5037 - loss: 71.0582 - val_accuracy: 0.4825 - val_loss: 35.8280\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.4967 - loss: 27.5236 - val_accuracy: 0.4800 - val_loss: 8.4121\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.4994 - loss: 5.3775 - val_accuracy: 0.4725 - val_loss: 1.0833\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5272 - loss: 0.9705 - val_accuracy: 0.5063 - val_loss: 0.8498\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.4817 - loss: 0.8465 - val_accuracy: 0.4913 - val_loss: 0.8427\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5001 - loss: 0.8435 - val_accuracy: 0.5050 - val_loss: 0.8430\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.4898 - loss: 0.8433 - val_accuracy: 0.4663 - val_loss: 0.8434\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5085 - loss: 0.8431 - val_accuracy: 0.4787 - val_loss: 0.8431\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5039 - loss: 0.8430 - val_accuracy: 0.5025 - val_loss: 0.8434\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4971 - loss: 0.8434\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-04 18:33:40,751] Trial 6 finished with value: 0.5 and parameters: {'num_layers': 6, 'filters_0': 81, 'filters_1': 120, 'filters_2': 116, 'filters_3': 105, 'filters_4': 59, 'filters_5': 112, 'kernel_size': 3, 'l1': 0.006603823222315412, 'l2': 0.002900513795476131, 'dense_units': 146, 'dropout_rate': 0.41997302492548794, 'learning_rate': 0.0004072581667211054}. Best is trial 0 with value: 0.6507499814033508.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 7 started with hyperparameters: num_layers=3, filters=[77, 116, 66], kernel_size=2, l1=0.0009818686340810788, l2=0.0055574421855256835, dense_units=187, dropout_rate=0.1317230125277924, learning_rate=0.0008096562501811213\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.4914 - loss: 4.2322 - val_accuracy: 0.4825 - val_loss: 2.6402\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5066 - loss: 2.3279 - val_accuracy: 0.4812 - val_loss: 1.6303\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5036 - loss: 1.5107 - val_accuracy: 0.4725 - val_loss: 1.2646\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4958 - loss: 1.2118 - val_accuracy: 0.5075 - val_loss: 1.0780\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5074 - loss: 1.0447 - val_accuracy: 0.5088 - val_loss: 0.9584\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4917 - loss: 0.9361 - val_accuracy: 0.4950 - val_loss: 0.8788\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5133 - loss: 0.8635 - val_accuracy: 0.4663 - val_loss: 0.8229\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5091 - loss: 0.8119 - val_accuracy: 0.4787 - val_loss: 0.7851\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5066 - loss: 0.7775 - val_accuracy: 0.5025 - val_loss: 0.7586\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4971 - loss: 0.7587\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-04 18:47:51,434] Trial 7 finished with value: 0.5 and parameters: {'num_layers': 3, 'filters_0': 77, 'filters_1': 116, 'filters_2': 66, 'kernel_size': 2, 'l1': 0.0009818686340810788, 'l2': 0.0055574421855256835, 'dense_units': 187, 'dropout_rate': 0.1317230125277924, 'learning_rate': 0.0008096562501811213}. Best is trial 0 with value: 0.6507499814033508.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 8 started with hyperparameters: num_layers=6, filters=[121, 90, 71, 128, 112, 109], kernel_size=3, l1=0.0018981462169385098, l2=4.1261149660181787e-05, dense_units=208, dropout_rate=0.14262679293217184, learning_rate=0.00022335554608512317\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 114ms/step - accuracy: 0.5012 - loss: 23.7731 - val_accuracy: 0.4825 - val_loss: 17.1137\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.5107 - loss: 15.2096 - val_accuracy: 0.4800 - val_loss: 10.0376\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.4937 - loss: 8.6329 - val_accuracy: 0.4725 - val_loss: 4.9626\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.4964 - loss: 4.0602 - val_accuracy: 0.5063 - val_loss: 1.9011\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.5071 - loss: 1.5024 - val_accuracy: 0.5088 - val_loss: 0.8198\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.5016 - loss: 0.7757 - val_accuracy: 0.5050 - val_loss: 0.7221\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.5029 - loss: 0.7208 - val_accuracy: 0.4663 - val_loss: 0.7192\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.5091 - loss: 0.7190 - val_accuracy: 0.4787 - val_loss: 0.7191\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.5066 - loss: 0.7189 - val_accuracy: 0.5025 - val_loss: 0.7190\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4971 - loss: 0.7190\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-04 19:02:12,880] Trial 8 finished with value: 0.5 and parameters: {'num_layers': 6, 'filters_0': 121, 'filters_1': 90, 'filters_2': 71, 'filters_3': 128, 'filters_4': 112, 'filters_5': 109, 'kernel_size': 3, 'l1': 0.0018981462169385098, 'l2': 4.1261149660181787e-05, 'dense_units': 208, 'dropout_rate': 0.14262679293217184, 'learning_rate': 0.00022335554608512317}. Best is trial 0 with value: 0.6507499814033508.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 9 started with hyperparameters: num_layers=4, filters=[90, 79, 89, 89], kernel_size=3, l1=0.0018049079483755707, l2=2.0755299715900565e-06, dense_units=215, dropout_rate=0.4540769502809594, learning_rate=4.437418904982602e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - accuracy: 0.5018 - loss: 11.7318 - val_accuracy: 0.4837 - val_loss: 11.1620\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.4964 - loss: 10.9793 - val_accuracy: 0.5838 - val_loss: 10.4298\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5397 - loss: 10.2522 - val_accuracy: 0.4762 - val_loss: 9.7335\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5282 - loss: 9.5619 - val_accuracy: 0.6325 - val_loss: 9.0581\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5399 - loss: 8.8983 - val_accuracy: 0.5050 - val_loss: 8.4258\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5456 - loss: 8.2722 - val_accuracy: 0.5425 - val_loss: 7.8271\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5641 - loss: 7.6792 - val_accuracy: 0.5537 - val_loss: 7.2623\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5453 - loss: 7.1317 - val_accuracy: 0.5425 - val_loss: 6.7279\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5851 - loss: 6.5921 - val_accuracy: 0.5938 - val_loss: 6.2152\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6126 - loss: 6.2128\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-04 19:16:43,056] Trial 9 finished with value: 0.6147500276565552 and parameters: {'num_layers': 4, 'filters_0': 90, 'filters_1': 79, 'filters_2': 89, 'filters_3': 89, 'kernel_size': 3, 'l1': 0.0018049079483755707, 'l2': 2.0755299715900565e-06, 'dense_units': 215, 'dropout_rate': 0.4540769502809594, 'learning_rate': 4.437418904982602e-05}. Best is trial 0 with value: 0.6507499814033508.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10 started with hyperparameters: num_layers=3, filters=[55, 57, 33], kernel_size=3, l1=1.3714743508594547e-05, l2=0.00016166631967919707, dense_units=246, dropout_rate=0.28202435845806834, learning_rate=0.00012923740943007048\n",
            "\u001b[1m48/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4982 - loss: 0.7548"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-04 19:18:15,998] Trial 10 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 11 started with hyperparameters: num_layers=4, filters=[98, 61, 89, 92], kernel_size=3, l1=2.0315537942732576e-05, l2=1.013174390493206e-06, dense_units=253, dropout_rate=0.3562699778711074, learning_rate=6.831377684582747e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5017 - loss: 0.8102"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 19:19:49,915] Trial 11 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 12 started with hyperparameters: num_layers=4, filters=[93, 33, 80, 107], kernel_size=3, l1=0.00032059494129308737, l2=7.700735055106116e-05, dense_units=176, dropout_rate=0.2404348225153734, learning_rate=0.00014549043508741327\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5062 - loss: 2.0193"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 19:21:25,109] Trial 12 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 13 started with hyperparameters: num_layers=4, filters=[96, 101, 103, 79], kernel_size=3, l1=2.885009823140431e-05, l2=0.00037230288571827165, dense_units=128, dropout_rate=0.4939953185961022, learning_rate=4.33571293850659e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5096 - loss: 1.0149"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 19:23:01,700] Trial 13 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 14 started with hyperparameters: num_layers=3, filters=[64, 71, 62], kernel_size=3, l1=2.1878287105007017e-06, l2=1.780138527833866e-05, dense_units=200, dropout_rate=0.36933172243735557, learning_rate=0.00025434666693325344\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5254 - loss: 0.7160"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 19:24:34,765] Trial 14 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 15 started with hyperparameters: num_layers=4, filters=[85, 45, 81, 121], kernel_size=3, l1=0.007253034846949363, l2=1.2242808651660255e-06, dense_units=221, dropout_rate=0.20611511960717066, learning_rate=1.0104664299774052e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.5026 - loss: 36.8778 - val_accuracy: 0.5175 - val_loss: 36.4501\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5032 - loss: 36.3103 - val_accuracy: 0.5200 - val_loss: 35.8851\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5067 - loss: 35.7453 - val_accuracy: 0.5763 - val_loss: 35.3249\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5065 - loss: 35.1864 - val_accuracy: 0.4950 - val_loss: 34.7695\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5164 - loss: 34.6315 - val_accuracy: 0.5088 - val_loss: 34.2176\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5135 - loss: 34.0815 - val_accuracy: 0.4950 - val_loss: 33.6721\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5019 - loss: 33.5365 - val_accuracy: 0.6263 - val_loss: 33.1296\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5382 - loss: 32.9956 - val_accuracy: 0.6313 - val_loss: 32.5929\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5268 - loss: 32.4600 - val_accuracy: 0.6012 - val_loss: 32.0606\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5981 - loss: 32.0605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 19:38:46,206] Trial 15 finished with value: 0.5979999899864197 and parameters: {'num_layers': 4, 'filters_0': 85, 'filters_1': 45, 'filters_2': 81, 'filters_3': 121, 'kernel_size': 3, 'l1': 0.007253034846949363, 'l2': 1.2242808651660255e-06, 'dense_units': 221, 'dropout_rate': 0.20611511960717066, 'learning_rate': 1.0104664299774052e-05}. Best is trial 0 with value: 0.6507499814033508.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 16 started with hyperparameters: num_layers=4, filters=[111, 67, 106, 82], kernel_size=3, l1=5.3592890515914255e-05, l2=0.0009521282165903795, dense_units=232, dropout_rate=0.3048368692517198, learning_rate=9.222811594538403e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4916 - loss: 1.2717"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 19:40:22,197] Trial 16 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 17 started with hyperparameters: num_layers=3, filters=[53, 102, 56], kernel_size=3, l1=5.505538299648664e-06, l2=0.00023593750109406053, dense_units=185, dropout_rate=0.3851180428299373, learning_rate=2.6509497194085158e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4915 - loss: 0.7515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 19:41:54,981] Trial 17 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 18 started with hyperparameters: num_layers=4, filters=[105, 74, 87, 102], kernel_size=3, l1=0.00039935402546442835, l2=2.744144361007307e-05, dense_units=129, dropout_rate=0.2776900919933366, learning_rate=0.00021495145391508638\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4964 - loss: 3.0869"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 19:43:30,862] Trial 18 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 19 started with hyperparameters: num_layers=5, filters=[87, 106, 73, 77, 32], kernel_size=3, l1=7.528061183642421e-05, l2=4.155005413091779e-06, dense_units=161, dropout_rate=0.48975684471043807, learning_rate=6.26064694720531e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5004 - loss: 1.2271"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 19:45:08,436] Trial 19 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 started with hyperparameters: num_layers=3, filters=[72, 48, 112], kernel_size=2, l1=3.569805953473113e-06, l2=8.723982782358374e-05, dense_units=201, dropout_rate=0.1828547235200355, learning_rate=2.9392044074171436e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4992 - loss: 0.7168"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 19:46:40,087] Trial 20 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 21 started with hyperparameters: num_layers=5, filters=[120, 79, 94, 60, 82], kernel_size=2, l1=8.89977332275106e-06, l2=0.001664620134252906, dense_units=165, dropout_rate=0.4319353202355606, learning_rate=1.1304574967167206e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5048 - loss: 1.2772"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 19:48:17,135] Trial 21 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 22 started with hyperparameters: num_layers=4, filters=[102, 97, 128, 93], kernel_size=2, l1=3.468247781489886e-05, l2=0.002423213067358153, dense_units=143, dropout_rate=0.402548900654826, learning_rate=1.5330226637885333e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5085 - loss: 1.6615"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 19:49:52,227] Trial 22 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 23 started with hyperparameters: num_layers=5, filters=[90, 110, 94, 116, 88], kernel_size=2, l1=9.343895494162638e-06, l2=0.0007553219937124926, dense_units=177, dropout_rate=0.4511969287776317, learning_rate=1.945550226904966e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5069 - loss: 1.0650"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 19:51:26,801] Trial 23 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 24 started with hyperparameters: num_layers=4, filters=[114, 125, 77, 65], kernel_size=2, l1=4.2915746113632035e-06, l2=0.008097615188714208, dense_units=231, dropout_rate=0.3310697701371276, learning_rate=3.9275479598952294e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.4850 - loss: 3.0006 - val_accuracy: 0.5138 - val_loss: 2.8908\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.5147 - loss: 2.8571 - val_accuracy: 0.4825 - val_loss: 2.7564\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5214 - loss: 2.7241 - val_accuracy: 0.4888 - val_loss: 2.6304\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.5143 - loss: 2.6005 - val_accuracy: 0.6375 - val_loss: 2.5105\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5479 - loss: 2.4832 - val_accuracy: 0.6000 - val_loss: 2.4006\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5258 - loss: 2.3756 - val_accuracy: 0.5200 - val_loss: 2.3014\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5487 - loss: 2.2738 - val_accuracy: 0.6000 - val_loss: 2.2054\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5394 - loss: 2.1888 - val_accuracy: 0.4812 - val_loss: 2.1258\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5883 - loss: 2.0973 - val_accuracy: 0.5900 - val_loss: 2.0374\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5915 - loss: 2.0363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 20:05:39,997] Trial 24 finished with value: 0.597000002861023 and parameters: {'num_layers': 4, 'filters_0': 114, 'filters_1': 125, 'filters_2': 77, 'filters_3': 65, 'kernel_size': 2, 'l1': 4.2915746113632035e-06, 'l2': 0.008097615188714208, 'dense_units': 231, 'dropout_rate': 0.3310697701371276, 'learning_rate': 3.9275479598952294e-05}. Best is trial 0 with value: 0.6507499814033508.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 25 started with hyperparameters: num_layers=5, filters=[59, 60, 87, 32, 121], kernel_size=3, l1=1.1520688628231588e-06, l2=0.0037330676886308273, dense_units=145, dropout_rate=0.4685164662142885, learning_rate=8.730035702610689e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5103 - loss: 1.5265"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 20:07:14,489] Trial 25 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 26 started with hyperparameters: num_layers=4, filters=[42, 78, 108, 91], kernel_size=2, l1=0.00010907024235598691, l2=0.0016922387384330105, dense_units=194, dropout_rate=0.4096283336810391, learning_rate=1.7028755580610168e-05\n",
            "\u001b[1m48/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4868 - loss: 1.5394"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 20:08:46,961] Trial 26 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 27 started with hyperparameters: num_layers=5, filters=[76, 87, 96, 114, 66], kernel_size=3, l1=0.00416907308130264, l2=0.00039673159205364666, dense_units=217, dropout_rate=0.3131464073569233, learning_rate=0.00013418581956140143\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 96ms/step - accuracy: 0.5047 - loss: 36.3963 - val_accuracy: 0.5175 - val_loss: 30.4948\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5051 - loss: 28.6781 - val_accuracy: 0.4837 - val_loss: 23.4782\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5105 - loss: 21.8975 - val_accuracy: 0.5288 - val_loss: 17.4084\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5181 - loss: 16.0647 - val_accuracy: 0.4938 - val_loss: 12.2875\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5078 - loss: 11.1804 - val_accuracy: 0.4913 - val_loss: 8.1146\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5080 - loss: 7.2430 - val_accuracy: 0.5050 - val_loss: 4.8825\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4993 - loss: 4.2462 - val_accuracy: 0.4663 - val_loss: 2.5907\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5091 - loss: 2.1892 - val_accuracy: 0.4787 - val_loss: 1.2411\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5066 - loss: 1.0726 - val_accuracy: 0.5025 - val_loss: 0.7710\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4971 - loss: 0.7711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 20:23:00,230] Trial 27 finished with value: 0.5 and parameters: {'num_layers': 5, 'filters_0': 76, 'filters_1': 87, 'filters_2': 96, 'filters_3': 114, 'filters_4': 66, 'kernel_size': 3, 'l1': 0.00416907308130264, 'l2': 0.00039673159205364666, 'dense_units': 217, 'dropout_rate': 0.3131464073569233, 'learning_rate': 0.00013418581956140143}. Best is trial 0 with value: 0.6507499814033508.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 28 started with hyperparameters: num_layers=6, filters=[106, 96, 85, 99, 93, 36], kernel_size=2, l1=0.0007205614464315885, l2=1.017806123650197e-05, dense_units=125, dropout_rate=0.26814687992250474, learning_rate=0.00035590581636867015\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 97ms/step - accuracy: 0.5232 - loss: 5.3721 - val_accuracy: 0.5175 - val_loss: 4.0915\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5165 - loss: 3.7168 - val_accuracy: 0.4800 - val_loss: 2.6893\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5007 - loss: 2.4060 - val_accuracy: 0.4725 - val_loss: 1.6583\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.4957 - loss: 1.4695 - val_accuracy: 0.5063 - val_loss: 1.0080\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5133 - loss: 0.9161 - val_accuracy: 0.4913 - val_loss: 0.7450\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5015 - loss: 0.7304 - val_accuracy: 0.5050 - val_loss: 0.7058\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.4846 - loss: 0.7040 - val_accuracy: 0.4663 - val_loss: 0.7006\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5024 - loss: 0.7000 - val_accuracy: 0.4787 - val_loss: 0.6992\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5037 - loss: 0.6989 - val_accuracy: 0.5025 - val_loss: 0.6985\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4971 - loss: 0.6985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 20:37:13,448] Trial 28 finished with value: 0.5 and parameters: {'num_layers': 6, 'filters_0': 106, 'filters_1': 96, 'filters_2': 85, 'filters_3': 99, 'filters_4': 93, 'filters_5': 36, 'kernel_size': 2, 'l1': 0.0007205614464315885, 'l2': 1.017806123650197e-05, 'dense_units': 125, 'dropout_rate': 0.26814687992250474, 'learning_rate': 0.00035590581636867015}. Best is trial 0 with value: 0.6507499814033508.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 29 started with hyperparameters: num_layers=5, filters=[119, 52, 102, 82, 126], kernel_size=3, l1=1.5488173218113703e-05, l2=0.0014269498193011146, dense_units=110, dropout_rate=0.32992348013633777, learning_rate=5.1802745298826076e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4970 - loss: 1.2846"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 20:38:49,656] Trial 29 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            "Value: 0.6507499814033508\n",
            "Params: \n",
            "    num_layers: 4\n",
            "    filters_0: 88\n",
            "    filters_1: 38\n",
            "    filters_2: 88\n",
            "    filters_3: 106\n",
            "    kernel_size: 3\n",
            "    l1: 1.5022150089120748e-05\n",
            "    l2: 0.0035801025371631446\n",
            "    dense_units: 193\n",
            "    dropout_rate: 0.2866844238417743\n",
            "    learning_rate: 0.00016920857191232494\n",
            "Elapsed time: 13502.07 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vfrLaMAGIB7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, regularizers, callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "import time\n",
        "import gzip\n",
        "import skimage.transform\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "\n",
        "# Configure logging to file in the current directory with the specified name\n",
        "logging.basicConfig(filename='Ancient_Scenarios_AW.log', level=logging.INFO,\n",
        "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
        "\n",
        "# Function to preprocess data\n",
        "def preprocess_data(simulations_folder, batch_number):\n",
        "    # Create ImaFile object for the specified simulation folder and model\n",
        "    file_sim = ImaFile(simulations_folder=os.path.join(simulations_folder, f'Simulations{batch_number}'), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "\n",
        "    # Read the simulation data\n",
        "    gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=4000)\n",
        "\n",
        "    # Filter simulations based on frequency threshold\n",
        "    gene_sim.filter_freq(0.01)\n",
        "\n",
        "    # Sort simulations by row frequency\n",
        "    gene_sim.sort('rows_freq')\n",
        "\n",
        "    # Resize simulation data to the required dimensions\n",
        "    gene_sim.resize((198, 192))\n",
        "\n",
        "    # Convert simulation data (flip=True allows for data augmentation)\n",
        "    gene_sim.convert(flip=True)\n",
        "\n",
        "    # Get a random subset of indices and subset the simulation data\n",
        "    gene_sim.subset(get_index_random(gene_sim))\n",
        "\n",
        "    # Convert targets to binary format\n",
        "    gene_sim.targets = to_binary(gene_sim.targets)\n",
        "\n",
        "    return gene_sim\n",
        "\n",
        "# Objective function for Optuna optimization\n",
        "def objective(trial, simulations_folder, epochs=1):\n",
        "    # Set random seed\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    # Hyperparameters to be optimized\n",
        "    num_layers = trial.suggest_int('num_layers', 3, 6)  # Limit the number of layers to avoid excessive reduction\n",
        "    filters = [trial.suggest_int(f'filters_{i}', 32, 128) for i in range(num_layers)]  # Adjust filters range\n",
        "    kernel_size = trial.suggest_int('kernel_size', 2, 3)  # Limit the kernel size to avoid excessive reduction\n",
        "    l1 = trial.suggest_float('l1', 1e-6, 1e-2, log=True)\n",
        "    l2 = trial.suggest_float('l2', 1e-6, 1e-2, log=True)\n",
        "    dense_units = trial.suggest_int('dense_units', 64, 256)  # Adjust dense units range\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
        "\n",
        "    # Log the hyperparameters at the start of each trial\n",
        "    logging.info(f'Trial {trial.number} started with hyperparameters: num_layers={num_layers}, filters={filters}, '\n",
        "                 f'kernel_size={kernel_size}, l1={l1}, l2={l2}, dense_units={dense_units}, '\n",
        "                 f'dropout_rate={dropout_rate}, learning_rate={learning_rate}')\n",
        "    print(f'Trial {trial.number} started with hyperparameters: num_layers={num_layers}, filters={filters}, '\n",
        "          f'kernel_size={kernel_size}, l1={l1}, l2={l2}, dense_units={dense_units}, '\n",
        "          f'dropout_rate={dropout_rate}, learning_rate={learning_rate}')\n",
        "\n",
        "    # Building the model based on sampled hyperparameters\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=(198, 192, 1)))  # Define the input layer\n",
        "    for i in range(num_layers):\n",
        "        model.add(layers.Conv2D(filters=filters[i], kernel_size=(kernel_size, kernel_size), strides=(1, 1), activation='relu',\n",
        "                                kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2), padding='same'))  # Use 'same' padding to avoid dimension issues\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())  # Flatten the output for the Dense layers\n",
        "    model.add(layers.Dense(units=dense_units, activation='relu'))  # Add Dense layer\n",
        "    model.add(layers.Dropout(rate=dropout_rate))  # Add Dropout layer\n",
        "    model.add(layers.Dense(units=1, activation='sigmoid'))  # Output layer with sigmoid activation\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)  # Define optimizer\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])  # Compile the model\n",
        "\n",
        "    # Pruning callback to terminate unpromising trials\n",
        "    pruning_callback = TFKerasPruningCallback(trial, 'val_loss')\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Incremental training on 9 batches\n",
        "    best_val_loss = np.inf  # Track the best validation loss\n",
        "    for batch_number in range(1, 10):\n",
        "        gene_sim = preprocess_data(simulations_folder, batch_number)  # Preprocess data\n",
        "        history = model.fit(gene_sim.data, gene_sim.targets, batch_size=64, epochs=epochs, verbose=1, validation_split=0.2,\n",
        "                            callbacks=[early_stopping, pruning_callback])  # Train the model with callbacks\n",
        "\n",
        "        # Get the validation loss for the current epoch\n",
        "        val_loss = min(history.history['val_loss'])\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            trial.report(val_loss, batch_number)\n",
        "            if trial.should_prune():\n",
        "                raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    # Evaluate the model on the 10th batch\n",
        "    gene_sim = preprocess_data(simulations_folder, 10)\n",
        "    evaluation = model.evaluate(gene_sim.data, gene_sim.targets, verbose=1)\n",
        "    return evaluation[1]  # Return the accuracy\n",
        "\n",
        "# Function to run the optimization process\n",
        "def run_optimization():\n",
        "    start_time = time.time()  # Record start time\n",
        "\n",
        "    simulations_folder = '/content/EvoNet-CNN-Insight/model_training/Ancient_weak/AW'  # Folder for this dataset\n",
        "    logging.info(f\"Starting optimization for {simulations_folder}\")\n",
        "    print(f\"Starting optimization for {simulations_folder}\")\n",
        "\n",
        "    # Create an Optuna study and optimize the objective function\n",
        "    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner(), storage='sqlite:///aw_study.db', load_if_exists=True)  # Use SQLite storage\n",
        "    study.optimize(lambda trial: objective(trial, simulations_folder), n_trials=30)  # Set to 30 trials\n",
        "\n",
        "    try:\n",
        "        trial = study.best_trial\n",
        "        print('Best trial:')\n",
        "        print('Value: {}'.format(trial.value))\n",
        "        print('Params: ')\n",
        "        for key, value in trial.params.items():\n",
        "            print('    {}: {}'.format(key, value))  # Print best trial parameters\n",
        "\n",
        "        logging.info('Best trial:')\n",
        "        logging.info('Value: {}'.format(trial.value))\n",
        "        logging.info('Params: ')\n",
        "        for key, value in trial.params.items():\n",
        "            logging.info('    {}: {}'.format(key, value))  # Log best trial parameters\n",
        "\n",
        "    except ValueError as e:\n",
        "        logging.error(f\"No completed trials: {e}\")  # Log error if no trials are completed\n",
        "\n",
        "    elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
        "    print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
        "    logging.info(f\"Elapsed time: {elapsed_time:.2f} seconds\")  # Log elapsed time\n",
        "\n",
        "# Run the optimization process\n",
        "if __name__ == '__main__':\n",
        "    run_optimization()  # Execute the optimization function\n"
      ],
      "metadata": {
        "id": "pljwmA8cICq1",
        "outputId": "1fcb301b-a531-444b-f301-1779710218aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting optimization for /content/EvoNet-CNN-Insight/model_training/Ancient_weak/AW\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 20:43:01,424] A new study created in RDB with name: no-name-e83c06ce-ce7b-44ee-a988-e1ccf1a89758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 started with hyperparameters: num_layers=3, filters=[32, 112, 80], kernel_size=2, l1=5.6564905040331065e-06, l2=0.0006596203709234314, dense_units=91, dropout_rate=0.22209327106425047, learning_rate=2.7822404420087316e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.5095 - loss: 0.8014 - val_accuracy: 0.5387 - val_loss: 0.7875\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6045 - loss: 0.7792 - val_accuracy: 0.6975 - val_loss: 0.7487\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6771 - loss: 0.7451 - val_accuracy: 0.6950 - val_loss: 0.7143\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6721 - loss: 0.7183 - val_accuracy: 0.7337 - val_loss: 0.6788\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6924 - loss: 0.6908 - val_accuracy: 0.7237 - val_loss: 0.6620\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7284 - loss: 0.6612 - val_accuracy: 0.7275 - val_loss: 0.6671\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7081 - loss: 0.6627 - val_accuracy: 0.7212 - val_loss: 0.6459\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6901 - loss: 0.6623 - val_accuracy: 0.7300 - val_loss: 0.6371\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7207 - loss: 0.6494 - val_accuracy: 0.7188 - val_loss: 0.6582\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7565 - loss: 0.6344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 20:56:54,247] Trial 0 finished with value: 0.7494999766349792 and parameters: {'num_layers': 3, 'filters_0': 32, 'filters_1': 112, 'filters_2': 80, 'kernel_size': 2, 'l1': 5.6564905040331065e-06, 'l2': 0.0006596203709234314, 'dense_units': 91, 'dropout_rate': 0.22209327106425047, 'learning_rate': 2.7822404420087316e-05}. Best is trial 0 with value: 0.7494999766349792.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 started with hyperparameters: num_layers=3, filters=[77, 37, 98], kernel_size=2, l1=1.372647917189269e-06, l2=0.0047751555805138944, dense_units=172, dropout_rate=0.1236472638677225, learning_rate=1.0186907345142566e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.5103 - loss: 1.1950 - val_accuracy: 0.4825 - val_loss: 1.1860\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5583 - loss: 1.1791 - val_accuracy: 0.7387 - val_loss: 1.1625\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6769 - loss: 1.1558 - val_accuracy: 0.5888 - val_loss: 1.1503\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6569 - loss: 1.1375 - val_accuracy: 0.7400 - val_loss: 1.1081\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7037 - loss: 1.1104 - val_accuracy: 0.7375 - val_loss: 1.0846\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7334 - loss: 1.0798 - val_accuracy: 0.7325 - val_loss: 1.0702\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7172 - loss: 1.0651 - val_accuracy: 0.6212 - val_loss: 1.0722\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6788 - loss: 1.0592 - val_accuracy: 0.7038 - val_loss: 1.0418\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7345 - loss: 1.0335 - val_accuracy: 0.7000 - val_loss: 1.0540\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7519 - loss: 1.0325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 21:10:49,603] Trial 1 finished with value: 0.7440000176429749 and parameters: {'num_layers': 3, 'filters_0': 77, 'filters_1': 37, 'filters_2': 98, 'kernel_size': 2, 'l1': 1.372647917189269e-06, 'l2': 0.0047751555805138944, 'dense_units': 172, 'dropout_rate': 0.1236472638677225, 'learning_rate': 1.0186907345142566e-05}. Best is trial 0 with value: 0.7494999766349792.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 started with hyperparameters: num_layers=3, filters=[79, 79, 125], kernel_size=2, l1=1.4238915610455433e-06, l2=0.0011892049877332892, dense_units=227, dropout_rate=0.2605345852243278, learning_rate=2.5834311151381096e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.5117 - loss: 0.9098 - val_accuracy: 0.6825 - val_loss: 0.8913\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5565 - loss: 0.8887 - val_accuracy: 0.7425 - val_loss: 0.8630\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6644 - loss: 0.8560 - val_accuracy: 0.7200 - val_loss: 0.8189\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6757 - loss: 0.8179 - val_accuracy: 0.6963 - val_loss: 0.7817\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7034 - loss: 0.7875 - val_accuracy: 0.7287 - val_loss: 0.7521\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7314 - loss: 0.7510 - val_accuracy: 0.7300 - val_loss: 0.7528\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7193 - loss: 0.7479 - val_accuracy: 0.6913 - val_loss: 0.7323\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6915 - loss: 0.7481 - val_accuracy: 0.7500 - val_loss: 0.7172\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7352 - loss: 0.7271 - val_accuracy: 0.7300 - val_loss: 0.7288\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7546 - loss: 0.7063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 21:24:49,147] Trial 2 finished with value: 0.7509999871253967 and parameters: {'num_layers': 3, 'filters_0': 79, 'filters_1': 79, 'filters_2': 125, 'kernel_size': 2, 'l1': 1.4238915610455433e-06, 'l2': 0.0011892049877332892, 'dense_units': 227, 'dropout_rate': 0.2605345852243278, 'learning_rate': 2.5834311151381096e-05}. Best is trial 2 with value: 0.7509999871253967.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 started with hyperparameters: num_layers=6, filters=[33, 38, 109, 93, 101, 101], kernel_size=2, l1=0.00038774904195475266, l2=0.0006237706192384797, dense_units=105, dropout_rate=0.39104611988171223, learning_rate=0.000310471523491917\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 77ms/step - accuracy: 0.5048 - loss: 3.2069 - val_accuracy: 0.5288 - val_loss: 2.6157\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6249 - loss: 2.4346 - val_accuracy: 0.7163 - val_loss: 1.9216\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7062 - loss: 1.8166 - val_accuracy: 0.7088 - val_loss: 1.5136\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7106 - loss: 1.4507 - val_accuracy: 0.7513 - val_loss: 1.2216\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7175 - loss: 1.2019 - val_accuracy: 0.7400 - val_loss: 1.0499\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7367 - loss: 1.0261 - val_accuracy: 0.6925 - val_loss: 1.0320\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7213 - loss: 0.9765 - val_accuracy: 0.7538 - val_loss: 0.9189\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6929 - loss: 0.9564 - val_accuracy: 0.7325 - val_loss: 0.9118\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7207 - loss: 0.9048 - val_accuracy: 0.7125 - val_loss: 0.8909\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7453 - loss: 0.8621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 21:38:54,524] Trial 3 finished with value: 0.7404999732971191 and parameters: {'num_layers': 6, 'filters_0': 33, 'filters_1': 38, 'filters_2': 109, 'filters_3': 93, 'filters_4': 101, 'filters_5': 101, 'kernel_size': 2, 'l1': 0.00038774904195475266, 'l2': 0.0006237706192384797, 'dense_units': 105, 'dropout_rate': 0.39104611988171223, 'learning_rate': 0.000310471523491917}. Best is trial 2 with value: 0.7509999871253967.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 4 started with hyperparameters: num_layers=4, filters=[47, 93, 49, 79], kernel_size=3, l1=1.2768768751592014e-06, l2=9.604232302132508e-06, dense_units=80, dropout_rate=0.26553158133657734, learning_rate=1.1214926892821376e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.5038 - loss: 0.7005 - val_accuracy: 0.6162 - val_loss: 0.6946\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5907 - loss: 0.6934 - val_accuracy: 0.6775 - val_loss: 0.6857\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6520 - loss: 0.6832 - val_accuracy: 0.6475 - val_loss: 0.6728\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6643 - loss: 0.6662 - val_accuracy: 0.7250 - val_loss: 0.6447\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6703 - loss: 0.6449 - val_accuracy: 0.7100 - val_loss: 0.6175\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7104 - loss: 0.6075 - val_accuracy: 0.7050 - val_loss: 0.6041\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6982 - loss: 0.5956 - val_accuracy: 0.6363 - val_loss: 0.6019\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6635 - loss: 0.6025 - val_accuracy: 0.6725 - val_loss: 0.5855\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7060 - loss: 0.5730 - val_accuracy: 0.6950 - val_loss: 0.5902\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7346 - loss: 0.5661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 21:52:57,553] Trial 4 finished with value: 0.7245000004768372 and parameters: {'num_layers': 4, 'filters_0': 47, 'filters_1': 93, 'filters_2': 49, 'filters_3': 79, 'kernel_size': 3, 'l1': 1.2768768751592014e-06, 'l2': 9.604232302132508e-06, 'dense_units': 80, 'dropout_rate': 0.26553158133657734, 'learning_rate': 1.1214926892821376e-05}. Best is trial 2 with value: 0.7509999871253967.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 started with hyperparameters: num_layers=5, filters=[64, 100, 76, 74, 55], kernel_size=2, l1=4.7021998031313704e-06, l2=0.005847866115271297, dense_units=159, dropout_rate=0.26717349703824117, learning_rate=2.5647740371392422e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 74ms/step - accuracy: 0.5138 - loss: 2.4715 - val_accuracy: 0.5475 - val_loss: 2.4223\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5438 - loss: 2.4072 - val_accuracy: 0.5725 - val_loss: 2.3592\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5729 - loss: 2.3441 - val_accuracy: 0.6525 - val_loss: 2.2991\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6138 - loss: 2.2840 - val_accuracy: 0.7462 - val_loss: 2.2368\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6781 - loss: 2.2240 - val_accuracy: 0.7362 - val_loss: 2.1737\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6929 - loss: 2.1580 - val_accuracy: 0.6850 - val_loss: 2.1140\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6718 - loss: 2.0947 - val_accuracy: 0.5138 - val_loss: 2.0710\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6242 - loss: 2.0436 - val_accuracy: 0.7163 - val_loss: 1.9842\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7137 - loss: 1.9734 - val_accuracy: 0.6888 - val_loss: 1.9515\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7301 - loss: 1.9328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 22:06:59,462] Trial 5 finished with value: 0.721750020980835 and parameters: {'num_layers': 5, 'filters_0': 64, 'filters_1': 100, 'filters_2': 76, 'filters_3': 74, 'filters_4': 55, 'kernel_size': 2, 'l1': 4.7021998031313704e-06, 'l2': 0.005847866115271297, 'dense_units': 159, 'dropout_rate': 0.26717349703824117, 'learning_rate': 2.5647740371392422e-05}. Best is trial 2 with value: 0.7509999871253967.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 6 started with hyperparameters: num_layers=6, filters=[66, 91, 91, 54, 45, 49], kernel_size=2, l1=0.005885485010007552, l2=1.2368614978249004e-06, dense_units=247, dropout_rate=0.3548034110646663, learning_rate=8.480036970285573e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 90ms/step - accuracy: 0.4918 - loss: 28.7152 - val_accuracy: 0.5175 - val_loss: 26.9722\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5076 - loss: 26.4090 - val_accuracy: 0.5750 - val_loss: 24.7407\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5420 - loss: 24.2016 - val_accuracy: 0.5537 - val_loss: 22.6094\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5573 - loss: 22.0947 - val_accuracy: 0.6438 - val_loss: 20.5760\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5941 - loss: 20.0862 - val_accuracy: 0.6837 - val_loss: 18.6419\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5950 - loss: 18.1770 - val_accuracy: 0.6425 - val_loss: 16.8085\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5932 - loss: 16.3682 - val_accuracy: 0.4950 - val_loss: 15.0739\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5321 - loss: 14.6586 - val_accuracy: 0.4787 - val_loss: 13.4389\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5137 - loss: 13.0484 - val_accuracy: 0.5025 - val_loss: 11.9044\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4971 - loss: 11.9043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 22:21:04,510] Trial 6 finished with value: 0.5 and parameters: {'num_layers': 6, 'filters_0': 66, 'filters_1': 91, 'filters_2': 91, 'filters_3': 54, 'filters_4': 45, 'filters_5': 49, 'kernel_size': 2, 'l1': 0.005885485010007552, 'l2': 1.2368614978249004e-06, 'dense_units': 247, 'dropout_rate': 0.3548034110646663, 'learning_rate': 8.480036970285573e-05}. Best is trial 2 with value: 0.7509999871253967.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 7 started with hyperparameters: num_layers=5, filters=[104, 33, 123, 128, 39], kernel_size=2, l1=2.9071198028236248e-05, l2=0.002187047619800581, dense_units=155, dropout_rate=0.19035707741227714, learning_rate=0.00034288667657427516\n",
            "\u001b[1m48/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5098 - loss: 1.3852"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 22:22:37,286] Trial 7 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 8 started with hyperparameters: num_layers=6, filters=[89, 96, 53, 63, 41, 67], kernel_size=3, l1=1.743786384843828e-06, l2=8.427905520864181e-05, dense_units=195, dropout_rate=0.2846863251383474, learning_rate=0.0005334940923780643\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4977 - loss: 0.7308"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 22:24:13,998] Trial 8 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 9 started with hyperparameters: num_layers=4, filters=[39, 57, 48, 80], kernel_size=2, l1=0.0026103694152217966, l2=9.983840514985239e-05, dense_units=128, dropout_rate=0.1530353337511684, learning_rate=1.9369894474490272e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.5063 - loss: 6.0601 - val_accuracy: 0.5238 - val_loss: 5.9899\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5550 - loss: 5.9694 - val_accuracy: 0.6637 - val_loss: 5.8995\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6267 - loss: 5.8777 - val_accuracy: 0.6313 - val_loss: 5.8101\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6486 - loss: 5.7868 - val_accuracy: 0.7500 - val_loss: 5.7139\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6965 - loss: 5.6958 - val_accuracy: 0.7325 - val_loss: 5.6209\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7140 - loss: 5.5993 - val_accuracy: 0.7175 - val_loss: 5.5379\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7053 - loss: 5.5130 - val_accuracy: 0.6400 - val_loss: 5.4586\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6448 - loss: 5.4453 - val_accuracy: 0.6500 - val_loss: 5.3817\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7067 - loss: 5.3548 - val_accuracy: 0.6950 - val_loss: 5.3137\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7371 - loss: 5.2963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 22:38:09,756] Trial 9 finished with value: 0.7292500138282776 and parameters: {'num_layers': 4, 'filters_0': 39, 'filters_1': 57, 'filters_2': 48, 'filters_3': 80, 'kernel_size': 2, 'l1': 0.0026103694152217966, 'l2': 9.983840514985239e-05, 'dense_units': 128, 'dropout_rate': 0.1530353337511684, 'learning_rate': 1.9369894474490272e-05}. Best is trial 2 with value: 0.7509999871253967.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 started with hyperparameters: num_layers=3, filters=[119, 68, 127], kernel_size=3, l1=8.639000203442336e-05, l2=1.500707489978116e-05, dense_units=255, dropout_rate=0.49174705734738106, learning_rate=8.083222418626741e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5250 - loss: 1.0891"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 22:39:42,766] Trial 10 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 11 started with hyperparameters: num_layers=3, filters=[56, 117, 74], kernel_size=2, l1=1.3104633651925766e-05, l2=0.0005933349337686679, dense_units=208, dropout_rate=0.21045573710426235, learning_rate=3.605953550845774e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5034 - loss: 0.8369"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 22:41:13,509] Trial 11 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 12 started with hyperparameters: num_layers=4, filters=[92, 122, 65, 40], kernel_size=2, l1=5.642743371473763e-06, l2=0.0006375409017782348, dense_units=85, dropout_rate=0.3512466822898067, learning_rate=3.454274744555845e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5041 - loss: 0.8685"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 22:42:46,366] Trial 12 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 13 started with hyperparameters: num_layers=3, filters=[122, 74, 88], kernel_size=2, l1=2.2717850938822887e-05, l2=0.0013922930377730828, dense_units=64, dropout_rate=0.21703552316314964, learning_rate=5.7890901571620457e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5163 - loss: 0.9965"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 22:44:18,135] Trial 13 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 14 started with hyperparameters: num_layers=4, filters=[74, 108, 108, 112], kernel_size=3, l1=0.0002574202522671307, l2=0.00022363880083939658, dense_units=210, dropout_rate=0.31875794218469505, learning_rate=0.0001613509668484967\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.5201 - loss: 2.7329 - val_accuracy: 0.5663 - val_loss: 2.3539\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6637 - loss: 2.2278 - val_accuracy: 0.7538 - val_loss: 1.9523\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7098 - loss: 1.8912 - val_accuracy: 0.7225 - val_loss: 1.6763\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7261 - loss: 1.6314 - val_accuracy: 0.7237 - val_loss: 1.5089\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6926 - loss: 1.5027 - val_accuracy: 0.7513 - val_loss: 1.3219\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7498 - loss: 1.3005 - val_accuracy: 0.7462 - val_loss: 1.2525\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7541 - loss: 1.2139 - val_accuracy: 0.7850 - val_loss: 1.1294\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7332 - loss: 1.1676 - val_accuracy: 0.7675 - val_loss: 1.1274\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7493 - loss: 1.1209 - val_accuracy: 0.7475 - val_loss: 1.1091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 22:56:58,823] Trial 14 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 15 started with hyperparameters: num_layers=3, filters=[49, 82, 63], kernel_size=2, l1=5.194639320195182e-06, l2=3.33773367955495e-05, dense_units=123, dropout_rate=0.4201248840417293, learning_rate=1.970617991092491e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5079 - loss: 0.7060"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 22:58:29,681] Trial 15 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 16 started with hyperparameters: num_layers=3, filters=[100, 57, 33], kernel_size=2, l1=6.551038976888805e-05, l2=0.00025136030610568356, dense_units=221, dropout_rate=0.2431845563910644, learning_rate=0.0009993930476508526\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5543 - loss: 0.8980"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 23:00:00,590] Trial 16 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 17 started with hyperparameters: num_layers=5, filters=[110, 110, 109, 32, 119], kernel_size=3, l1=3.960703512523192e-06, l2=0.0025069456632635183, dense_units=181, dropout_rate=0.1648643098014621, learning_rate=4.980470275530553e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5189 - loss: 1.5106"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 23:01:39,004] Trial 17 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 18 started with hyperparameters: num_layers=4, filters=[89, 85, 88, 106], kernel_size=2, l1=1.1969658585844553e-05, l2=0.007936867011278357, dense_units=143, dropout_rate=0.3123689867532133, learning_rate=0.00013397016701278662\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.5288 - loss: 2.8058 - val_accuracy: 0.6825 - val_loss: 2.4840\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6748 - loss: 2.3800 - val_accuracy: 0.7337 - val_loss: 2.1135\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7135 - loss: 2.0556 - val_accuracy: 0.7312 - val_loss: 1.8592\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7281 - loss: 1.8467 - val_accuracy: 0.7862 - val_loss: 1.6747\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7448 - loss: 1.6777 - val_accuracy: 0.7225 - val_loss: 1.5821\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7461 - loss: 1.5555 - val_accuracy: 0.7300 - val_loss: 1.5123\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7517 - loss: 1.4528 - val_accuracy: 0.7650 - val_loss: 1.3709\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7347 - loss: 1.3890 - val_accuracy: 0.7788 - val_loss: 1.2957\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7331 - loss: 1.3213 - val_accuracy: 0.7400 - val_loss: 1.2755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 23:14:22,450] Trial 18 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 19 started with hyperparameters: num_layers=3, filters=[63, 59, 99], kernel_size=2, l1=0.0005291710273615084, l2=0.00026442816434863326, dense_units=239, dropout_rate=0.126467290049805, learning_rate=1.5300447441843284e-05\n",
            "\u001b[1m48/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5048 - loss: 1.7782"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 23:15:54,126] Trial 19 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 started with hyperparameters: num_layers=4, filters=[128, 126, 68, 123], kernel_size=3, l1=1.0771307585473345e-06, l2=0.0010899936187889145, dense_units=98, dropout_rate=0.2438449000550495, learning_rate=3.4582234344104575e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5103 - loss: 1.0279"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 23:17:30,692] Trial 20 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 21 started with hyperparameters: num_layers=3, filters=[80, 44, 117], kernel_size=2, l1=2.777757015003424e-06, l2=0.003325155193437487, dense_units=181, dropout_rate=0.10691728758754662, learning_rate=1.0663780032957135e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5281 - loss: 1.1054"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 23:19:01,411] Trial 21 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 22 started with hyperparameters: num_layers=3, filters=[74, 50, 99], kernel_size=2, l1=2.2292717946368963e-06, l2=0.00988792988528563, dense_units=234, dropout_rate=0.16694297650988332, learning_rate=1.4530137279857798e-05\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.5202 - loss: 1.9550 - val_accuracy: 0.4825 - val_loss: 1.9323\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5596 - loss: 1.9208 - val_accuracy: 0.6900 - val_loss: 1.8878\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6799 - loss: 1.8787 - val_accuracy: 0.6187 - val_loss: 1.8587\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6433 - loss: 1.8427 - val_accuracy: 0.6963 - val_loss: 1.7994\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6955 - loss: 1.7985 - val_accuracy: 0.7175 - val_loss: 1.7601\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7227 - loss: 1.7510 - val_accuracy: 0.7200 - val_loss: 1.7427\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7055 - loss: 1.7346 - val_accuracy: 0.6300 - val_loss: 1.7343\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6649 - loss: 1.7234 - val_accuracy: 0.7063 - val_loss: 1.6891\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7118 - loss: 1.6880 - val_accuracy: 0.6950 - val_loss: 1.7033\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7358 - loss: 1.6775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 23:33:00,793] Trial 22 finished with value: 0.7275000214576721 and parameters: {'num_layers': 3, 'filters_0': 74, 'filters_1': 50, 'filters_2': 99, 'kernel_size': 2, 'l1': 2.2292717946368963e-06, 'l2': 0.00988792988528563, 'dense_units': 234, 'dropout_rate': 0.16694297650988332, 'learning_rate': 1.4530137279857798e-05}. Best is trial 2 with value: 0.7509999871253967.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 23 started with hyperparameters: num_layers=3, filters=[80, 70, 82], kernel_size=2, l1=9.263200059431897e-06, l2=0.0038342274268266707, dense_units=180, dropout_rate=0.135607711185187, learning_rate=2.3326711626829587e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5098 - loss: 1.2979"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 23:34:31,899] Trial 23 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 24 started with hyperparameters: num_layers=3, filters=[54, 106, 98], kernel_size=2, l1=1.1696017000163084e-06, l2=0.0012780414889432758, dense_units=134, dropout_rate=0.10115085204000313, learning_rate=1.035244291879792e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5065 - loss: 0.9215"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 23:36:03,146] Trial 24 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 25 started with hyperparameters: num_layers=4, filters=[32, 75, 117, 52], kernel_size=2, l1=3.384862799336577e-05, l2=0.0003699539830926601, dense_units=112, dropout_rate=0.20023947401814896, learning_rate=2.8112700730005784e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5043 - loss: 0.8811"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 23:37:34,353] Trial 25 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 26 started with hyperparameters: num_layers=3, filters=[43, 117, 103], kernel_size=2, l1=2.316745906437951e-06, l2=0.0013406482637932846, dense_units=171, dropout_rate=0.24755644589404902, learning_rate=5.157626498609322e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5068 - loss: 0.9457"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 23:39:05,873] Trial 26 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 27 started with hyperparameters: num_layers=4, filters=[72, 63, 81, 91], kernel_size=2, l1=6.223690811081266e-06, l2=0.0033255635665438684, dense_units=146, dropout_rate=0.17460397369010866, learning_rate=1.5822685141375934e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5241 - loss: 1.4609"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 23:40:37,289] Trial 27 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 28 started with hyperparameters: num_layers=3, filters=[96, 48, 118], kernel_size=2, l1=2.593774609648388e-06, l2=0.0001665345041415093, dense_units=197, dropout_rate=0.29508920580027626, learning_rate=4.151554702128399e-05\n",
            "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5074 - loss: 0.7296"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 23:42:08,657] Trial 28 pruned. Trial was pruned at epoch 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 29 started with hyperparameters: num_layers=5, filters=[86, 39, 94, 107, 79], kernel_size=2, l1=0.00030344891195144437, l2=0.0005471693294126225, dense_units=225, dropout_rate=0.44225500363817927, learning_rate=0.00012994004948262334\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 75ms/step - accuracy: 0.4940 - loss: 2.2494 - val_accuracy: 0.4825 - val_loss: 2.1026\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5460 - loss: 2.0551 - val_accuracy: 0.7113 - val_loss: 1.9151\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6433 - loss: 1.8620 - val_accuracy: 0.7063 - val_loss: 1.6658\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7064 - loss: 1.6231 - val_accuracy: 0.7325 - val_loss: 1.4950\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7119 - loss: 1.4873 - val_accuracy: 0.7400 - val_loss: 1.3936\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7357 - loss: 1.3727 - val_accuracy: 0.7262 - val_loss: 1.3215\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7341 - loss: 1.2982 - val_accuracy: 0.7475 - val_loss: 1.2380\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7332 - loss: 1.2337 - val_accuracy: 0.7600 - val_loss: 1.1630\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7333 - loss: 1.1703 - val_accuracy: 0.7188 - val_loss: 1.1430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-04 23:54:45,786] Trial 29 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            "Value: 0.7509999871253967\n",
            "Params: \n",
            "    num_layers: 3\n",
            "    filters_0: 79\n",
            "    filters_1: 79\n",
            "    filters_2: 125\n",
            "    kernel_size: 2\n",
            "    l1: 1.4238915610455433e-06\n",
            "    l2: 0.0011892049877332892\n",
            "    dense_units: 227\n",
            "    dropout_rate: 0.2605345852243278\n",
            "    learning_rate: 2.5834311151381096e-05\n",
            "Elapsed time: 11504.60 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tz3bZsOhKY7b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}