{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK3KvnjK-QcE"
      },
      "source": [
        "Data Analysis Pipeline:\n",
        "\n",
        "\n",
        "*  Clone the repo to carry the dependencies over and to invoke imagene.py.\n",
        "*  Import all necessary modules.\n",
        "\n",
        "\n",
        "*   Simulate data for ancient and moderate strength selection selrange = seq 0 200 200 / timerange = 0.1 100kya\n",
        "*   Build and compile baseline model.\n",
        "\n",
        "\n",
        "*   Train model on training data and gather metrics.\n",
        "\n",
        "*   Test trained network on unseen data.\n",
        "*  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloning the GitHub repository\n",
        "!git clone https://github.com/Djinho/EvoNet-CNN-Insight.git\n",
        "\n",
        "# Change directories into the specified directory\n",
        "%cd EvoNet-CNN-Insight/Model_training_3/Ancient_moderate\n",
        "\n"
      ],
      "metadata": {
        "id": "R_VVQbWtDaI-",
        "outputId": "f540b424-9d70-4c3a-af24-ee96b45989b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EvoNet-CNN-Insight'...\n",
            "remote: Enumerating objects: 2536, done.\u001b[K\n",
            "remote: Counting objects: 100% (409/409), done.\u001b[K\n",
            "remote: Compressing objects: 100% (301/301), done.\u001b[K\n",
            "remote: Total 2536 (delta 203), reused 216 (delta 108), pack-reused 2127\u001b[K\n",
            "Receiving objects: 100% (2536/2536), 4.62 GiB | 29.18 MiB/s, done.\n",
            "Resolving deltas: 100% (589/589), done.\n",
            "Updating files: 100% (379/379), done.\n",
            "/content/EvoNet-CNN-Insight/Model_training_3/Ancient_moderate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T9u8r4IE-QcG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gzip\n",
        "import _pickle as pickle\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import arviz\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, optimizers, regularizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.transform\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, roc_curve, auc\n",
        "import pydot  # Optional, but required by keras to plot the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KgbCr3IL-QcH"
      },
      "outputs": [],
      "source": [
        "%run -i ../ImaGene.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtD-SiZf-QcK"
      },
      "source": [
        "ImaGene uses msms to run simulations for training. Use ../generate_dataset.sh with ../params.txt (modify as needed).\n",
        "\n",
        " simulates 200,000 loci (80kbp) under neutral evolution or positive selection (1.5% selection coefficient). Mutation rate: 1.5e-8, recombination rate: 1e-8. Model follows Marth et al. 2004, sampling 198 chromosomal copies.\n",
        "\n",
        "Specify directories for msms and simulation storage, then run the command. The script splits simulations into batches for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpJ0fu9--QcK"
      },
      "outputs": [],
      "source": [
        "# if you wish to generate new training data, do not run otherwise\n",
        "import subprocess\n",
        "subprocess.call(\"bash ../generate_dataset.sh params_ANT_moderate.txt\".split());"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = './'"
      ],
      "metadata": {
        "id": "znzk6fGjIbiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utIwRbBK-QcK"
      },
      "outputs": [],
      "source": [
        "\n",
        "path_sim = './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MchXp6DQ-QcK"
      },
      "outputs": [],
      "source": [
        "file_sim = ImaFile(simulations_folder=path_sim + 'AM/Simulations1', nr_samples=198, model_name='Marth-3epoch-CEU');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF_VYGM9-QcK"
      },
      "source": [
        "Populate an ImaGene object by specifying the variable to estimate (selection_coeff_hetero) and the number of data points per class. Use 8000 data points per class as an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WJsx4eN-QcK"
      },
      "outputs": [],
      "source": [
        "gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=8000);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FGJbyMg-QcL"
      },
      "outputs": [],
      "source": [
        "gene_sim.filter_freq(0.01);\n",
        "gene_sim.sort('rows_freq');\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tYlmeE6-QcL"
      },
      "outputs": [],
      "source": [
        "gene_sim.resize((198, 192));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhxn9cgB-QcL"
      },
      "outputs": [],
      "source": [
        "gene_sim.convert(flip=True);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VXYbA4b-QcM"
      },
      "source": [
        "shuffle images before using them for training network.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSV9FO0y-QcM"
      },
      "outputs": [],
      "source": [
        "gene_sim.subset(get_index_random(gene_sim));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WT-e8RG1-QcM"
      },
      "outputs": [],
      "source": [
        "gene_sim.targets = to_binary(gene_sim.targets);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "li1KC-KV-QcM"
      },
      "outputs": [],
      "source": [
        "gene_sim.save(file=path + 'gene_sim.binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si67YCk1-QcM"
      },
      "outputs": [],
      "source": [
        "gene_sim = load_imagene(file=path + 'gene_sim.binary')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UgXTkAj-_VBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "space = {\n",
        "    'num_layers': hp.choice('num_layers', [1, 2, 3]),\n",
        "    'filters_1': hp.choice('filters_1', [32, 64, 128]),\n",
        "    'filters_2': hp.choice('filters_2', [32, 64, 128]),\n",
        "    'filters_3': hp.choice('filters_3', [64, 128, 256]),\n",
        "    'kernel_size': hp.choice('kernel_size', [(3,3), (5,5), (7,7)]),\n",
        "    'pool_size': hp.choice('pool_size', [(2,2), (3,3)]),\n",
        "    'dense_units': hp.choice('dense_units', [64, 128, 256]),\n",
        "    'dropout': hp.uniform('dropout', 0.2, 0.5),\n",
        "    'learning_rate': hp.loguniform('learning_rate', -4, -2)\n",
        "}\n"
      ],
      "metadata": {
        "id": "pTuE9PHv_VSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(params):\n",
        "    # Preprocess the data for training batches\n",
        "    losses = []\n",
        "    val_losses = []\n",
        "    accuracies = []\n",
        "    val_accuracies = []\n",
        "    total_epochs = 0\n",
        "\n",
        "    for i in range(1, 10):\n",
        "        file_sim = ImaFile(simulations_folder=path_sim + 'AM/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "        gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=8000)\n",
        "\n",
        "        gene_sim.filter_freq(0.01)\n",
        "        gene_sim.sort('rows_freq')\n",
        "        gene_sim.resize((198, 192))\n",
        "        gene_sim.convert(flip=True)\n",
        "\n",
        "        gene_sim.subset(get_index_random(gene_sim))\n",
        "        gene_sim.targets = to_binary(gene_sim.targets)\n",
        "\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Conv2D(filters=int(params['filters_1']), kernel_size=params['kernel_size'], activation='relu', input_shape=gene_sim.data.shape[1:]))\n",
        "        model.add(layers.MaxPooling2D(pool_size=params['pool_size']))\n",
        "\n",
        "        if params['num_layers'] > 1:\n",
        "            model.add(layers.Conv2D(filters=int(params['filters_2']), kernel_size=params['kernel_size'], activation='relu'))\n",
        "            model.add(layers.MaxPooling2D(pool_size=params['pool_size']))\n",
        "\n",
        "        if params['num_layers'] > 2:\n",
        "            model.add(layers.Conv2D(filters=int(params['filters_3']), kernel_size=params['kernel"
      ],
      "metadata": {
        "id": "2-xz4jre_WAO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}